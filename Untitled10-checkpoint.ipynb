{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b88856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Year Month Day   kingdom   latitude  longitude  Avg_Temperature  \\\n",
      "0   1  2011    04  01   Arcadia  24.280002 -37.229980            25.50   \n",
      "1   2  2011    04  01  Atlantis  22.979999 -37.329990           299.65   \n",
      "2   3  2011    04  01    Avalon  22.880000 -37.130006            26.30   \n",
      "3   4  2011    04  01   Camelot  24.180003 -36.929994            24.00   \n",
      "4   5  2011    04  01     Dorne  25.780002 -37.530000            28.00   \n",
      "\n",
      "   Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                       30.50                8.5   \n",
      "1                      305.15                5.9   \n",
      "2                       31.50                5.2   \n",
      "3                       28.40                8.2   \n",
      "4                       32.80                5.7   \n",
      "\n",
      "   Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                          10.3      22.52        58.89             16   \n",
      "1                           8.2      22.73        11.83             12   \n",
      "2                           6.4      22.73        11.83             12   \n",
      "3                          10.7      22.67        75.27             16   \n",
      "4                          10.2      22.35         4.81              8   \n",
      "\n",
      "   Wind_Speed  Wind_Direction  Evapotranspiration       date  \n",
      "0         8.6             283            1.648659 2011-04-01  \n",
      "1        15.8             161            1.583094 2011-04-01  \n",
      "2        15.8             161            1.593309 2011-04-01  \n",
      "3         6.4             346            1.638997 2011-04-01  \n",
      "4        16.7             185            1.719189 2011-04-01  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1724</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">110,400</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m12\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m2,368\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │          \u001b[38;5;34m12,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_1 (\u001b[38;5;33mAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ attention_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1724\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m110,400\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m33\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,657</span> (522.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m133,657\u001b[0m (522.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,657</span> (522.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,657\u001b[0m (522.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 29ms/step - loss: 0.0283 - mae: 0.1165 - val_loss: 0.0058 - val_mae: 0.0493\n",
      "Epoch 2/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 31ms/step - loss: 0.0071 - mae: 0.0542 - val_loss: 0.0035 - val_mae: 0.0377\n",
      "Epoch 3/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0049 - mae: 0.0431 - val_loss: 0.0027 - val_mae: 0.0306\n",
      "Epoch 4/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0041 - mae: 0.0380 - val_loss: 0.0024 - val_mae: 0.0292\n",
      "Epoch 5/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0037 - mae: 0.0351 - val_loss: 0.0024 - val_mae: 0.0284\n",
      "Epoch 6/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 28ms/step - loss: 0.0034 - mae: 0.0332 - val_loss: 0.0026 - val_mae: 0.0311\n",
      "Epoch 7/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0031 - mae: 0.0309 - val_loss: 0.0026 - val_mae: 0.0310\n",
      "Epoch 8/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0028 - mae: 0.0294 - val_loss: 0.0020 - val_mae: 0.0248\n",
      "Epoch 9/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0030 - mae: 0.0296 - val_loss: 0.0021 - val_mae: 0.0243\n",
      "Epoch 10/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 0.0027 - mae: 0.0283 - val_loss: 0.0017 - val_mae: 0.0218\n",
      "Epoch 11/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 0.0024 - mae: 0.0261 - val_loss: 0.0017 - val_mae: 0.0212\n",
      "Epoch 12/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0024 - mae: 0.0262 - val_loss: 0.0017 - val_mae: 0.0230\n",
      "Epoch 13/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0023 - mae: 0.0252 - val_loss: 0.0016 - val_mae: 0.0216\n",
      "Epoch 14/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0024 - mae: 0.0257 - val_loss: 0.0017 - val_mae: 0.0210\n",
      "Epoch 15/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0023 - mae: 0.0257 - val_loss: 0.0017 - val_mae: 0.0230\n",
      "Epoch 16/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0244 - val_loss: 0.0015 - val_mae: 0.0208\n",
      "Epoch 17/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0245 - val_loss: 0.0017 - val_mae: 0.0236\n",
      "Epoch 18/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 0.0020 - mae: 0.0235 - val_loss: 0.0018 - val_mae: 0.0222\n",
      "Epoch 19/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0247 - val_loss: 0.0014 - val_mae: 0.0195\n",
      "Epoch 20/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0021 - mae: 0.0234 - val_loss: 0.0013 - val_mae: 0.0187\n",
      "Epoch 21/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0021 - mae: 0.0230 - val_loss: 0.0015 - val_mae: 0.0182\n",
      "Epoch 22/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0020 - mae: 0.0228 - val_loss: 0.0014 - val_mae: 0.0211\n",
      "Epoch 23/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0223 - val_loss: 0.0020 - val_mae: 0.0258\n",
      "Epoch 24/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0226 - val_loss: 0.0014 - val_mae: 0.0184\n",
      "Epoch 25/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0018 - mae: 0.0217 - val_loss: 0.0014 - val_mae: 0.0181\n",
      "Epoch 26/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 30ms/step - loss: 0.0018 - mae: 0.0219 - val_loss: 0.0015 - val_mae: 0.0188\n",
      "Epoch 27/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0017 - mae: 0.0211 - val_loss: 0.0013 - val_mae: 0.0191\n",
      "Epoch 28/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 27ms/step - loss: 0.0018 - mae: 0.0218 - val_loss: 0.0013 - val_mae: 0.0191\n",
      "Epoch 29/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0017 - mae: 0.0207 - val_loss: 0.0014 - val_mae: 0.0196\n",
      "Epoch 30/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0018 - mae: 0.0215 - val_loss: 0.0015 - val_mae: 0.0201\n",
      "Epoch 31/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 0.0017 - mae: 0.0206 - val_loss: 0.0013 - val_mae: 0.0183\n",
      "Epoch 32/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0017 - mae: 0.0211 - val_loss: 0.0016 - val_mae: 0.0217\n",
      "Epoch 33/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0017 - mae: 0.0208 - val_loss: 0.0013 - val_mae: 0.0187\n",
      "Epoch 34/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0018 - mae: 0.0213 - val_loss: 0.0012 - val_mae: 0.0170\n",
      "Epoch 35/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0016 - mae: 0.0202 - val_loss: 0.0014 - val_mae: 0.0192\n",
      "Epoch 36/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0016 - mae: 0.0200 - val_loss: 0.0012 - val_mae: 0.0189\n",
      "Epoch 37/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0197 - val_loss: 0.0012 - val_mae: 0.0178\n",
      "Epoch 38/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0192 - val_loss: 0.0015 - val_mae: 0.0203\n",
      "Epoch 39/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 0.0016 - mae: 0.0201 - val_loss: 0.0014 - val_mae: 0.0197\n",
      "Epoch 40/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0016 - mae: 0.0201 - val_loss: 0.0012 - val_mae: 0.0172\n",
      "Epoch 41/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 26ms/step - loss: 0.0016 - mae: 0.0196 - val_loss: 0.0011 - val_mae: 0.0168\n",
      "Epoch 42/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - loss: 0.0015 - mae: 0.0197 - val_loss: 0.0012 - val_mae: 0.0187\n",
      "Epoch 43/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 26ms/step - loss: 0.0016 - mae: 0.0197 - val_loss: 0.0011 - val_mae: 0.0164\n",
      "Epoch 44/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 0.0011 - val_mae: 0.0155\n",
      "Epoch 45/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 30ms/step - loss: 0.0015 - mae: 0.0189 - val_loss: 0.0011 - val_mae: 0.0172\n",
      "Epoch 46/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 0.0015 - mae: 0.0194 - val_loss: 0.0012 - val_mae: 0.0170\n",
      "Epoch 47/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 0.0014 - val_mae: 0.0197\n",
      "Epoch 48/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 0.0012 - val_mae: 0.0163\n",
      "Epoch 49/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 0.0015 - val_mae: 0.0196\n",
      "Epoch 50/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0193 - val_loss: 0.0015 - val_mae: 0.0219\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "cannot assemble the datetimes: time data '90101' does not match format '%Y%m%d' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_assemble_from_unit_mappings\u001b[1;34m(arg, errors, tz)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1214\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%Y%m%d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1215\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m         \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0mcache_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[1;31m# GH#45319\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         res = _to_datetime_with_format(\n\u001b[0m\u001b[0;32m    431\u001b[0m             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_arg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;31m# fallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m     res = _array_strptime_with_fallback(\n\u001b[0m\u001b[0;32m    539\u001b[0m         \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimezones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_strptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data '90101' does not match format '%Y%m%d' (match)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31368\\3466396186.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;31m# Convert Year, Month, Day to datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Year'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Month'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Day'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;31m# Drop unnecessary columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_assemble_from_unit_mappings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m         \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_assemble_from_unit_mappings\u001b[1;34m(arg, errors, tz)\u001b[0m\n\u001b[0;32m   1214\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%Y%m%d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"cannot assemble the datetimes: {err}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m     \u001b[0munits\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnitChoices\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"h\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"m\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ms\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"us\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ns\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot assemble the datetimes: time data '90101' does not match format '%Y%m%d' (match)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, Attention\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------- #\n",
    "# Load and Preprocess Training Data\n",
    "# ------------------------------- #\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\train.csv\")\n",
    "\n",
    "# Define the starting year (adjust this based on the dataset)\n",
    "base_year = 2010  # If Year 1 corresponds to 2016\n",
    "\n",
    "# Convert Year values\n",
    "df['Year'] = df['Year'] + base_year\n",
    "\n",
    "# Ensure Month and Day are correctly formatted\n",
    "df['Month'] = df['Month'].astype(str).str.zfill(2)\n",
    "df['Day'] = df['Day'].astype(str).str.zfill(2)\n",
    "\n",
    "# Convert to proper datetime format\n",
    "df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
    "\n",
    "print(df.head())  # Check the output\n",
    "\n",
    "\n",
    "# Convert Year, Month, Day to datetime\n",
    "df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df.drop(columns=['date']))\n",
    "\n",
    "# Convert to DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns[1:])\n",
    "\n",
    "# ------------------------------- #\n",
    "# Create Time Series Sequences\n",
    "# ------------------------------- #\n",
    "TIME_STEPS = 30   # Past 30 days as input\n",
    "PREDICT_HORIZON = 1  # Predicting 1 day ahead\n",
    "\n",
    "def create_sequences(data, time_steps=TIME_STEPS, predict_horizon=PREDICT_HORIZON):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps - predict_horizon):\n",
    "        X.append(data.iloc[i: i + time_steps].values)\n",
    "        y.append(data.iloc[i + time_steps + predict_horizon - 1, 0])  # Predicting Avg_Temperature\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(scaled_df)\n",
    "\n",
    "# Train-test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# ------------------------------- #\n",
    "# Build CNN-LSTM-Attention Model\n",
    "# ------------------------------- #\n",
    "\n",
    "# Define model input\n",
    "input_layer = Input(shape=(TIME_STEPS, X_train.shape[2]))\n",
    "\n",
    "# CNN Layers\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(50, return_sequences=True)(input_layer)\n",
    "\n",
    "# Attention Layer\n",
    "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
    "attention_output = Flatten()(attention_layer)\n",
    "\n",
    "# Merge CNN and LSTM outputs\n",
    "merged = tf.keras.layers.Concatenate()([flatten, attention_output])\n",
    "\n",
    "# Dense Layers\n",
    "dense1 = Dense(64, activation='relu')(merged)\n",
    "dropout1 = Dropout(0.2)(dense1)\n",
    "dense2 = Dense(32, activation='relu')(dropout1)\n",
    "output_layer = Dense(1)(dense2)  # Predicting Avg_Temperature\n",
    "\n",
    "# Build Model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Train the Model\n",
    "# ------------------------------- #\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Prepare Test Data for Prediction\n",
    "# ------------------------------- #\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\")\n",
    "\n",
    "# Convert Year, Month, Day to datetime\n",
    "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "test_df = test_df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
    "\n",
    "# Merge with last known training data (to get missing feature values)\n",
    "last_train_data = df[df['date'] <= test_df['date'].min()]  # Get last available data\n",
    "test_df = test_df.merge(last_train_data, on='date', how='left')\n",
    "\n",
    "# Fill missing values using forward fill\n",
    "test_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Normalize test data\n",
    "scaled_test_data = scaler.transform(test_df.drop(columns=['date']))\n",
    "\n",
    "# Convert test data into sequences\n",
    "X_test_seq, _ = create_sequences(pd.DataFrame(scaled_test_data, columns=test_df.columns[1:]))\n",
    "\n",
    "# ------------------------------- #\n",
    "# Make Predictions\n",
    "# ------------------------------- #\n",
    "predictions = model.predict(X_test_seq)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "predicted_temp = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Save predictions\n",
    "test_df['Predicted_Temperature'] = predicted_temp\n",
    "test_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "011a6477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  Year Month Day   kingdom       date\n",
      "0  84961  2019    01  01   Arcadia 2019-01-01\n",
      "1  84962  2019    01  01  Atlantis 2019-01-01\n",
      "2  84963  2019    01  01    Avalon 2019-01-01\n",
      "3  84964  2019    01  01   Camelot 2019-01-01\n",
      "4  84965  2019    01  01     Dorne 2019-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isitha\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Day\n",
      "- ID\n",
      "- Month\n",
      "- Year\n",
      "- kingdom\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 17 features, but MinMaxScaler is expecting 12 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31368\\3500932844.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# Normalize test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mscaled_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Convert test data into sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 17 features, but MinMaxScaler is expecting 12 features as input."
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\")\n",
    "\n",
    "\n",
    "# Define the starting year (adjust this based on the dataset)\n",
    "base_year = 2010  # If Year 1 corresponds to 2016\n",
    "\n",
    "# Convert Year values\n",
    "test_df['Year'] = test_df['Year'] + base_year\n",
    "\n",
    "# Ensure Month and Day are correctly formatted\n",
    "test_df['Month'] = test_df['Month'].astype(str).str.zfill(2)\n",
    "test_df['Day'] = test_df['Day'].astype(str).str.zfill(2)\n",
    "\n",
    "# Convert to proper datetime format\n",
    "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
    "\n",
    "print(test_df.head())  # Check the output\n",
    "\n",
    "# Convert Year, Month, Day to datetime\n",
    "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "test_df = test_df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
    "\n",
    "# Merge with last known training data (to get missing feature values)\n",
    "last_train_data = df[df['date'] <= test_df['date'].min()]  # Get last available data\n",
    "test_df = test_df.merge(last_train_data, on='date', how='left')\n",
    "\n",
    "# Fill missing values using forward fill\n",
    "test_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Normalize test data\n",
    "scaled_test_data = scaler.transform(test_df.drop(columns=['date']))\n",
    "\n",
    "# Convert test data into sequences\n",
    "X_test_seq, _ = create_sequences(pd.DataFrame(scaled_test_data, columns=test_df.columns[1:]))\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------- #\n",
    "# Make Predictions\n",
    "# ------------------------------- #\n",
    "predictions = model.predict(X_test_seq)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "predicted_temp = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Save predictions\n",
    "test_df['Predicted_Temperature'] = predicted_temp\n",
    "test_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2dbbecc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing columns in test data: ['Avg_Temperature', 'Avg_Feels_Like_Temperature', 'Temperature_Range', 'Feels_Like_Temperature_Range', 'Radiation', 'Rain_Amount', 'Rain_Duration', 'Wind_Speed', 'Wind_Direction', 'Evapotranspiration']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31368\\3990918635.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Missing columns in test data: {missing_columns}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Check for extra columns in test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Missing columns in test data: ['Avg_Temperature', 'Avg_Feels_Like_Temperature', 'Temperature_Range', 'Feels_Like_Temperature_Range', 'Radiation', 'Rain_Amount', 'Rain_Duration', 'Wind_Speed', 'Wind_Direction', 'Evapotranspiration']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming you already have your trained model and scaler\n",
    "# Load the test data\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\")\n",
    "\n",
    "# Map the Year column (1-8) to actual years (e.g., 2016 to 2023)\n",
    "base_year = 2015  # If Year 1 corresponds to 2016\n",
    "test_df['Year'] = test_df['Year'] + base_year\n",
    "\n",
    "# Ensure Month and Day are in proper format\n",
    "test_df['Month'] = test_df['Month'].astype(str).str.zfill(2)\n",
    "test_df['Day'] = test_df['Day'].astype(str).str.zfill(2)\n",
    "\n",
    "# Create the date column\n",
    "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
    "\n",
    "# Drop unnecessary columns (those not used for prediction)\n",
    "test_df = test_df.drop(columns=['ID', 'Year', 'Month', 'Day', 'kingdom', 'date'])\n",
    "\n",
    "# Ensure columns in the test data match those in the training data\n",
    "required_columns = ['Avg_Temperature', 'Avg_Feels_Like_Temperature', 'Temperature_Range', \n",
    "                    'Feels_Like_Temperature_Range', 'Radiation', 'Rain_Amount', 'Rain_Duration', \n",
    "                    'Wind_Speed', 'Wind_Direction', 'Evapotranspiration']  # Add the exact list from training\n",
    "missing_columns = [col for col in required_columns if col not in test_df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing columns in test data: {missing_columns}\")\n",
    "\n",
    "# Check for extra columns in test data\n",
    "extra_columns = [col for col in test_df.columns if col not in required_columns]\n",
    "if extra_columns:\n",
    "    print(f\"Warning: Extra columns in test data that are not used for prediction: {extra_columns}\")\n",
    "    test_df = test_df[required_columns]  # Remove extra columns\n",
    "\n",
    "# Normalize the test data using the same scaler used during training\n",
    "scaled_test_data = scaler.transform(test_df)\n",
    "\n",
    "# Convert test data into sequences (same as for training)\n",
    "X_test_seq, _ = create_sequences(pd.DataFrame(scaled_test_data, columns=test_df.columns))\n",
    "\n",
    "# Predict using the trained model\n",
    "predictions = model.predict(X_test_seq)\n",
    "\n",
    "# If you need to inverse the scaling\n",
    "predicted_values = scaler.inverse_transform(predictions)\n",
    "\n",
    "# You can extract the predicted values for each of the variables\n",
    "predicted_temp = predicted_values[:, 0]  # Assuming temperature is the first column in your predictions\n",
    "\n",
    "# Adding predictions to the test DataFrame (you can add other variables similarly)\n",
    "test_df['Predicted_Temperature'] = predicted_temp\n",
    "\n",
    "# Optionally, save the predictions to a CSV\n",
    "test_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "# Print the first few rows of the predictions\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "905316d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Feels_Like_Temperature</th>\n",
       "      <th>Temperature_Range</th>\n",
       "      <th>Feels_Like_Temperature_Range</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Rain_Amount</th>\n",
       "      <th>Rain_Duration</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Wind_Direction</th>\n",
       "      <th>Evapotranspiration</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>01</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "      <td>25.50</td>\n",
       "      <td>30.50</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>22.52</td>\n",
       "      <td>58.89</td>\n",
       "      <td>16</td>\n",
       "      <td>8.6</td>\n",
       "      <td>283</td>\n",
       "      <td>1.648659</td>\n",
       "      <td>2011-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>01</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>22.979999</td>\n",
       "      <td>-37.329990</td>\n",
       "      <td>299.65</td>\n",
       "      <td>305.15</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>22.73</td>\n",
       "      <td>11.83</td>\n",
       "      <td>12</td>\n",
       "      <td>15.8</td>\n",
       "      <td>161</td>\n",
       "      <td>1.583094</td>\n",
       "      <td>2011-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>01</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>22.880000</td>\n",
       "      <td>-37.130006</td>\n",
       "      <td>26.30</td>\n",
       "      <td>31.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>22.73</td>\n",
       "      <td>11.83</td>\n",
       "      <td>12</td>\n",
       "      <td>15.8</td>\n",
       "      <td>161</td>\n",
       "      <td>1.593309</td>\n",
       "      <td>2011-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>01</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.180003</td>\n",
       "      <td>-36.929994</td>\n",
       "      <td>24.00</td>\n",
       "      <td>28.40</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>22.67</td>\n",
       "      <td>75.27</td>\n",
       "      <td>16</td>\n",
       "      <td>6.4</td>\n",
       "      <td>346</td>\n",
       "      <td>1.638997</td>\n",
       "      <td>2011-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>04</td>\n",
       "      <td>01</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>25.780002</td>\n",
       "      <td>-37.530000</td>\n",
       "      <td>28.00</td>\n",
       "      <td>32.80</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>22.35</td>\n",
       "      <td>4.81</td>\n",
       "      <td>8</td>\n",
       "      <td>16.7</td>\n",
       "      <td>185</td>\n",
       "      <td>1.719189</td>\n",
       "      <td>2011-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84955</th>\n",
       "      <td>84956</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>25.479998</td>\n",
       "      <td>-36.329990</td>\n",
       "      <td>25.60</td>\n",
       "      <td>28.60</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>19.41</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>90</td>\n",
       "      <td>1.562346</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84956</th>\n",
       "      <td>84957</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>26.580005</td>\n",
       "      <td>-37.530000</td>\n",
       "      <td>25.80</td>\n",
       "      <td>28.90</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>20.98</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.3</td>\n",
       "      <td>91</td>\n",
       "      <td>1.607436</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84957</th>\n",
       "      <td>84958</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-37.630006</td>\n",
       "      <td>298.75</td>\n",
       "      <td>301.65</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>71</td>\n",
       "      <td>1.710188</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84958</th>\n",
       "      <td>84959</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-35.729980</td>\n",
       "      <td>25.60</td>\n",
       "      <td>28.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>19.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>54</td>\n",
       "      <td>1.613430</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84959</th>\n",
       "      <td>84960</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "      <td>20.10</td>\n",
       "      <td>21.50</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>21.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>53</td>\n",
       "      <td>1.539015</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84960 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Year Month Day  kingdom   latitude  longitude  Avg_Temperature  \\\n",
       "0          1  2011    04  01  Arcadia  24.280002 -37.229980            25.50   \n",
       "1          2  2011    04  01  Arcadia  22.979999 -37.329990           299.65   \n",
       "2          3  2011    04  01  Arcadia  22.880000 -37.130006            26.30   \n",
       "3          4  2011    04  01  Arcadia  24.180003 -36.929994            24.00   \n",
       "4          5  2011    04  01  Arcadia  25.780002 -37.530000            28.00   \n",
       "...      ...   ...   ...  ..      ...        ...        ...              ...   \n",
       "84955  84956  2018    12  31  Arcadia  25.479998 -36.329990            25.60   \n",
       "84956  84957  2018    12  31  Arcadia  26.580005 -37.530000            25.80   \n",
       "84957  84958  2018    12  31  Arcadia  23.979999 -37.630006           298.75   \n",
       "84958  84959  2018    12  31  Arcadia  24.280002 -35.729980            25.60   \n",
       "84959  84960  2018    12  31  Arcadia  23.979999 -36.429994            20.10   \n",
       "\n",
       "       Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
       "0                           30.50                8.5   \n",
       "1                          305.15                5.9   \n",
       "2                           31.50                5.2   \n",
       "3                           28.40                8.2   \n",
       "4                           32.80                5.7   \n",
       "...                           ...                ...   \n",
       "84955                       28.60                3.4   \n",
       "84956                       28.90                2.8   \n",
       "84957                      301.65                7.6   \n",
       "84958                       28.10                4.0   \n",
       "84959                       21.50                8.4   \n",
       "\n",
       "       Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
       "0                              10.3      22.52        58.89             16   \n",
       "1                               8.2      22.73        11.83             12   \n",
       "2                               6.4      22.73        11.83             12   \n",
       "3                              10.7      22.67        75.27             16   \n",
       "4                              10.2      22.35         4.81              8   \n",
       "...                             ...        ...          ...            ...   \n",
       "84955                           3.5      19.41         0.13              1   \n",
       "84956                           3.7      20.98         0.26              2   \n",
       "84957                           9.2      22.67         0.00              0   \n",
       "84958                           3.8      19.72         0.00              0   \n",
       "84959                          11.1      21.31         0.00              0   \n",
       "\n",
       "       Wind_Speed  Wind_Direction  Evapotranspiration       date  \n",
       "0             8.6             283            1.648659 2011-04-01  \n",
       "1            15.8             161            1.583094 2011-04-01  \n",
       "2            15.8             161            1.593309 2011-04-01  \n",
       "3             6.4             346            1.638997 2011-04-01  \n",
       "4            16.7             185            1.719189 2011-04-01  \n",
       "...           ...             ...                 ...        ...  \n",
       "84955        14.8              90            1.562346 2018-12-31  \n",
       "84956        16.3              91            1.607436 2018-12-31  \n",
       "84957        12.6              71            1.710188 2018-12-31  \n",
       "84958        16.3              54            1.613430 2018-12-31  \n",
       "84959         9.4              53            1.539015 2018-12-31  \n",
       "\n",
       "[84960 rows x 18 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"kingdom\"] == \"Arcadia\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947637d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa31ff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global training data shape: (67230, 30, 48), (67230, 5)\n",
      "Global testing data shape: (16830, 30, 48), (16830, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,280</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_4               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">28,928</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_5               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1184</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">151,680</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Avg_Temperature (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Radiation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Rain_Amount (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Wind_Speed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Wind_Direction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m48\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m9,280\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_4               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m28,928\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │          \u001b[38;5;34m12,416\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_5               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_2 (\u001b[38;5;33mAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ attention_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1184\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m151,680\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Avg_Temperature (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m33\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Radiation (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m33\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Rain_Amount (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m33\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Wind_Speed (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m33\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ Wind_Direction (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m33\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227,301</span> (887.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m227,301\u001b[0m (887.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227,301</span> (887.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m227,301\u001b[0m (887.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For a model with multiple outputs, when providing the `metrics` argument as a list, it should have as many entries as the model has outputs. Received:\nmetrics=['mae']\nof length 1 whereas the model has 5 outputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31368\\1127617520.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[0mX_train_all\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0my_train_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\u001b[0m in \u001b[0;36m_build_metrics_set\u001b[1;34m(self, metrics, num_outputs, output_names, y_true, y_pred, argument_name)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    255\u001b[0m                         \u001b[1;34m\"For a model with multiple outputs, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                         \u001b[1;34mf\"when providing the `{argument_name}` argument as a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: For a model with multiple outputs, when providing the `metrics` argument as a list, it should have as many entries as the model has outputs. Received:\nmetrics=['mae']\nof length 1 whereas the model has 5 outputs."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, Attention, concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------- #\n",
    "# Load and Preprocess Training Data\n",
    "# ------------------------------- #\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\cleaned_data.csv\")\n",
    "\n",
    "# Define the starting year (adjust this based on the dataset)\n",
    "base_year = 2011  # If Year 1 corresponds to 2010\n",
    "\n",
    "# Convert Year values\n",
    "df['Year'] = df['Year'] + base_year - 1  # Subtracted 1 because Year 1 = 2010\n",
    "\n",
    "# Convert to proper datetime format\n",
    "df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values(by=['date', 'kingdom']).reset_index(drop=True)\n",
    "\n",
    "# Extract target variables\n",
    "target_variables = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']\n",
    "\n",
    "# Add kingdom as categorical feature using one-hot encoding\n",
    "kingdom_dummies = pd.get_dummies(df['kingdom'], prefix='kingdom')\n",
    "df = pd.concat([df, kingdom_dummies], axis=1)\n",
    "\n",
    "# Add cyclical encoding for month, day and wind direction\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['Month']/12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['Month']/12)\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['Day']/31)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['Day']/31)\n",
    "df['wind_dir_sin'] = np.sin(2 * np.pi * df['Wind_Direction']/360)\n",
    "df['wind_dir_cos'] = np.cos(2 * np.pi * df['Wind_Direction']/360)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_model = df.drop(columns=['ID', 'Year', 'Month', 'Day', 'kingdom', 'date'])\n",
    "\n",
    "# Check for any temperature values in Kelvin and convert them to Celsius if needed\n",
    "temp_cols = ['Avg_Temperature', 'Avg_Feels_Like_Temperature']\n",
    "for col in temp_cols:\n",
    "    # If temperatures are in Kelvin (values around 300)\n",
    "    if df_model[col].median() > 100:\n",
    "        df_model[col] = df_model[col] - 273.15\n",
    "        print(f\"Converted {col} from Kelvin to Celsius\")\n",
    "\n",
    "# Scale all features\n",
    "scaler = {}\n",
    "scaled_df = pd.DataFrame()\n",
    "\n",
    "# Scale each feature individually\n",
    "for col in df_model.columns:\n",
    "    scaler[col] = MinMaxScaler()\n",
    "    scaled_df[col] = scaler[col].fit_transform(df_model[col].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Create a dictionary to store kingdom data\n",
    "kingdom_data = {}\n",
    "kingdoms = df['kingdom'].unique()\n",
    "\n",
    "for kingdom in kingdoms:\n",
    "    kingdom_data[kingdom] = scaled_df[df['kingdom'] == kingdom].reset_index(drop=True)\n",
    "\n",
    "# ------------------------------- #\n",
    "# Create Time Series Sequences per Kingdom\n",
    "# ------------------------------- #\n",
    "TIME_STEPS = 30   # Past 30 days as input\n",
    "PREDICT_HORIZON = 1  # Predicting 1 day ahead\n",
    "\n",
    "def create_sequences_multitarget(data, targets, time_steps=TIME_STEPS, predict_horizon=PREDICT_HORIZON):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps - predict_horizon + 1):\n",
    "        X.append(data.iloc[i: i + time_steps].values)\n",
    "        y.append(data.iloc[i + time_steps + predict_horizon - 1][targets].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create model data per kingdom\n",
    "X_kingdom = {}\n",
    "y_kingdom = {}\n",
    "X_train_kingdom = {}\n",
    "X_test_kingdom = {}\n",
    "y_train_kingdom = {}\n",
    "y_test_kingdom = {}\n",
    "\n",
    "for kingdom in kingdoms:\n",
    "    X_kingdom[kingdom], y_kingdom[kingdom] = create_sequences_multitarget(\n",
    "        kingdom_data[kingdom], \n",
    "        target_variables, \n",
    "        TIME_STEPS, \n",
    "        PREDICT_HORIZON\n",
    "    )\n",
    "    \n",
    "    # Train-test split (80-20)\n",
    "    split = int(0.8 * len(X_kingdom[kingdom]))\n",
    "    X_train_kingdom[kingdom] = X_kingdom[kingdom][:split]\n",
    "    X_test_kingdom[kingdom] = X_kingdom[kingdom][split:]\n",
    "    y_train_kingdom[kingdom] = y_kingdom[kingdom][:split]\n",
    "    y_test_kingdom[kingdom] = y_kingdom[kingdom][split:]\n",
    "\n",
    "# Combine all kingdom data for a global model\n",
    "X_train_all = np.vstack([X_train_kingdom[k] for k in kingdoms])\n",
    "y_train_all = np.vstack([y_train_kingdom[k] for k in kingdoms])\n",
    "X_test_all = np.vstack([X_test_kingdom[k] for k in kingdoms])\n",
    "y_test_all = np.vstack([y_test_kingdom[k] for k in kingdoms])\n",
    "\n",
    "print(f\"Global training data shape: {X_train_all.shape}, {y_train_all.shape}\")\n",
    "print(f\"Global testing data shape: {X_test_all.shape}, {y_test_all.shape}\")\n",
    "\n",
    "# ------------------------------- #\n",
    "# Build Hybrid CNN-LSTM-Attention Model\n",
    "# ------------------------------- #\n",
    "\n",
    "def build_model(input_shape, output_size=5):\n",
    "    # Define model input\n",
    "    input_layer = Input(shape=(input_shape[1], input_shape[2]))\n",
    "    \n",
    "    # CNN Branch\n",
    "    conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "    cnn_flat = Flatten()(pool2)\n",
    "    \n",
    "    # LSTM Branch with Attention\n",
    "    lstm1 = LSTM(64, return_sequences=True)(input_layer)\n",
    "    lstm2 = LSTM(32, return_sequences=True)(lstm1)\n",
    "    \n",
    "    attention = Attention()([lstm2, lstm2])\n",
    "    lstm_flat = Flatten()(attention)\n",
    "    \n",
    "    # Merge branches\n",
    "    merged = concatenate([cnn_flat, lstm_flat])\n",
    "    \n",
    "    # Shared layers\n",
    "    dense1 = Dense(128, activation='relu')(merged)\n",
    "    dropout1 = Dropout(0.3)(dense1)\n",
    "    dense2 = Dense(64, activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.2)(dense2)\n",
    "    \n",
    "    # Individual output branches for each target\n",
    "    outputs = []\n",
    "    output_names = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']\n",
    "    \n",
    "    for i in range(output_size):\n",
    "        output_dense = Dense(32, activation='relu')(dropout2)\n",
    "        output = Dense(1, name=output_names[i])(output_dense)\n",
    "        outputs.append(output)\n",
    "    \n",
    "    # Build Model\n",
    "    model = Model(inputs=input_layer, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss='mse', \n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model(X_train_all.shape, len(target_variables))\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Train the Model\n",
    "# ------------------------------- #\n",
    "# Create callbacks for early stopping and model checkpointing\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_all, \n",
    "    [y_train_all[:, i] for i in range(y_train_all.shape[1])],\n",
    "    validation_data=(\n",
    "        X_test_all, \n",
    "        [y_test_all[:, i] for i in range(y_test_all.shape[1])]\n",
    "    ),\n",
    "    epochs=100, \n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, var in enumerate(target_variables):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.plot(history.history[f'{var}_loss'], label=f'Train {var}')\n",
    "    plt.plot(history.history[f'val_{var}_loss'], label=f'Validation {var}')\n",
    "    plt.title(f'{var} Loss')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_loss.png')\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Evaluate Model\n",
    "# ------------------------------- #\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_all)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_original = np.zeros((len(predictions[0]), len(target_variables)))\n",
    "y_test_original = np.zeros((len(y_test_all), len(target_variables)))\n",
    "\n",
    "for i, var in enumerate(target_variables):\n",
    "    y_pred_original[:, i] = scaler[var].inverse_transform(predictions[i]).flatten()\n",
    "    y_test_original[:, i] = scaler[var].inverse_transform(y_test_all[:, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "for i, var in enumerate(target_variables):\n",
    "    mse = mean_squared_error(y_test_original[:, i], y_pred_original[:, i])\n",
    "    mae = mean_absolute_error(y_test_original[:, i], y_pred_original[:, i])\n",
    "    r2 = r2_score(y_test_original[:, i], y_pred_original[:, i])\n",
    "    \n",
    "    print(f\"\\n{var} Evaluation:\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# ------------------------------- #\n",
    "# Prepare Final Test Data for Prediction\n",
    "# ------------------------------- #\n",
    "def prepare_test_data(test_df, train_df, scaler_dict, kingdoms, time_steps=TIME_STEPS):\n",
    "    # Convert to datetime\n",
    "    test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']])\n",
    "    \n",
    "    # Sort test data\n",
    "    test_df = test_df.sort_values(by=['date', 'kingdom']).reset_index(drop=True)\n",
    "    \n",
    "    # Get unique test dates\n",
    "    test_dates = test_df['date'].unique()\n",
    "    \n",
    "    # Create dictionary to store test sequences by kingdom\n",
    "    X_test_sequences = {}\n",
    "    test_ids = {}\n",
    "    \n",
    "    for kingdom in kingdoms:\n",
    "        # Get kingdom specific training data\n",
    "        kingdom_train = train_df[train_df['kingdom'] == kingdom].sort_values('date')\n",
    "        \n",
    "        # Get kingdom specific test data\n",
    "        kingdom_test = test_df[test_df['kingdom'] == kingdom].sort_values('date')\n",
    "        test_ids[kingdom] = kingdom_test['ID'].values\n",
    "        \n",
    "        # We need to create a buffer of historical data for each prediction\n",
    "        # For the first test date, use the last TIME_STEPS records from training\n",
    "        last_train_data = kingdom_train.tail(time_steps)\n",
    "        \n",
    "        # Create cyclical features on kingdom test data\n",
    "        kingdom_test['month_sin'] = np.sin(2 * np.pi * kingdom_test['Month']/12)\n",
    "        kingdom_test['month_cos'] = np.cos(2 * np.pi * kingdom_test['Month']/12)\n",
    "        kingdom_test['day_sin'] = np.sin(2 * np.pi * kingdom_test['Day']/31)\n",
    "        kingdom_test['day_cos'] = np.cos(2 * np.pi * kingdom_test['Day']/31)\n",
    "        \n",
    "        # Since Wind_Direction is missing, we'll use the average values from training\n",
    "        kingdom_test['wind_dir_sin'] = last_train_data['wind_dir_sin'].mean()\n",
    "        kingdom_test['wind_dir_cos'] = last_train_data['wind_dir_cos'].mean()\n",
    "        \n",
    "        # Add kingdom one-hot encoding\n",
    "        for k in kingdoms:\n",
    "            kingdom_test[f'kingdom_{k}'] = 1 if k == kingdom else 0\n",
    "        \n",
    "        # Get all the feature columns\n",
    "        feature_cols = [col for col in train_df.columns if col not in \n",
    "                       ['ID', 'Year', 'Month', 'Day', 'kingdom', 'date']]\n",
    "        \n",
    "        # Create an empty dataframe for storing scaled test data\n",
    "        kingdom_test_scaled = pd.DataFrame()\n",
    "        \n",
    "        # Scale each feature individually using the training scalers\n",
    "        for col in feature_cols:\n",
    "            if col in kingdom_test.columns:\n",
    "                # If the column exists in test data, scale it\n",
    "                kingdom_test_scaled[col] = scaler_dict[col].transform(\n",
    "                    kingdom_test[col].values.reshape(-1, 1)\n",
    "                ).flatten()\n",
    "            else:\n",
    "                # If column is missing (likely one of our targets), use last known values\n",
    "                # which will be updated as we make predictions\n",
    "                kingdom_test_scaled[col] = scaler_dict[col].transform(\n",
    "                    last_train_data[col].values.reshape(-1, 1)\n",
    "                ).iloc[-1]\n",
    "        \n",
    "        # Create a buffer that starts with training data and will be updated with predictions\n",
    "        buffer = pd.DataFrame(scaler_dict[feature_cols[0]].transform(\n",
    "            last_train_data[feature_cols].values\n",
    "        ), columns=feature_cols)\n",
    "        \n",
    "        # List to store test sequences\n",
    "        test_sequences = []\n",
    "        \n",
    "        # For each test date\n",
    "        for date in test_dates:\n",
    "            # Get test data for current date\n",
    "            current_test = kingdom_test_scaled[kingdom_test['date'] == date]\n",
    "            \n",
    "            if len(current_test) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Create sequence from buffer\n",
    "            sequence = buffer.tail(time_steps).values\n",
    "            test_sequences.append(sequence)\n",
    "            \n",
    "            # Update buffer with current test data (will be updated with predictions later)\n",
    "            buffer = pd.concat([buffer, current_test])\n",
    "        \n",
    "        X_test_sequences[kingdom] = np.array(test_sequences)\n",
    "    \n",
    "    return X_test_sequences, test_ids\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\")\n",
    "\n",
    "# Convert Year values\n",
    "test_df['Year'] = test_df['Year'] + base_year - 1\n",
    "\n",
    "# Prepare test sequences\n",
    "X_test_sequences, test_ids = prepare_test_data(test_df, df, scaler, kingdoms)\n",
    "\n",
    "# Make predictions for each kingdom\n",
    "submission_data = []\n",
    "\n",
    "for kingdom in kingdoms:\n",
    "    if len(X_test_sequences[kingdom]) > 0:\n",
    "        # Make predictions\n",
    "        kingdom_predictions = model.predict(X_test_sequences[kingdom])\n",
    "        \n",
    "        # Convert predictions back to original scale\n",
    "        kingdom_pred_original = np.zeros((len(kingdom_predictions[0]), len(target_variables)))\n",
    "        \n",
    "        for i, var in enumerate(target_variables):\n",
    "            kingdom_pred_original[:, i] = scaler[var].inverse_transform(\n",
    "                kingdom_predictions[i]\n",
    "            ).flatten()\n",
    "        \n",
    "        # Create submission entries\n",
    "        for j in range(len(test_ids[kingdom])):\n",
    "            submission_data.append({\n",
    "                'ID': test_ids[kingdom][j],\n",
    "                'Avg_Temperature': kingdom_pred_original[j, 0],\n",
    "                'Radiation': kingdom_pred_original[j, 1],\n",
    "                'Rain_Amount': kingdom_pred_original[j, 2],\n",
    "                'Wind_Speed': kingdom_pred_original[j, 3],\n",
    "                'Wind_Direction': kingdom_pred_original[j, 4]\n",
    "            })\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "\n",
    "# Save predictions\n",
    "submission_df.to_csv('predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad8db837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_6               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,600</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_7               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1724</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">110,400</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m12\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m2,368\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_6               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │          \u001b[38;5;34m12,600\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_7               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_3 (\u001b[38;5;33mAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_3 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1724\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m110,400\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m165\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,789</span> (522.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m133,789\u001b[0m (522.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,789</span> (522.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,789\u001b[0m (522.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 12 and 5 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, functional_3_1/dense_15_1/BiasAdd)' with input shapes: [?,12], [?,5].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31368\\2532771148.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;31m# Train the Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# ------------------------------- #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;31m# Plot Training Loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\losses\\losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m   1677\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m     \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqueeze_or_expand_to_same_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1679\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 12 and 5 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, functional_3_1/dense_15_1/BiasAdd)' with input shapes: [?,12], [?,5]."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, Attention\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------- #\n",
    "# Load and Preprocess Training Data\n",
    "# ------------------------------- #\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\cleaned_data.csv\")\n",
    "\n",
    "# Convert Year values\n",
    "base_year = 2010\n",
    "df['Year'] = df['Year'] + base_year\n",
    "\n",
    "# Convert to proper datetime format\n",
    "df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df.drop(columns=['date']))\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns[1:])\n",
    "\n",
    "# ------------------------------- #\n",
    "# Create Time Series Sequences\n",
    "# ------------------------------- #\n",
    "TIME_STEPS = 30\n",
    "PREDICT_HORIZON = 1\n",
    "\n",
    "def create_sequences(data, time_steps=TIME_STEPS, predict_horizon=PREDICT_HORIZON):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps - predict_horizon):\n",
    "        X.append(data.iloc[i: i + time_steps].values)\n",
    "        y.append(data.iloc[i + time_steps + predict_horizon - 1].values)  # Predict all 5 variables\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(scaled_df)\n",
    "\n",
    "# Train-test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# ------------------------------- #\n",
    "# Build CNN-LSTM-Attention Model\n",
    "# ------------------------------- #\n",
    "input_layer = Input(shape=(TIME_STEPS, X_train.shape[2]))\n",
    "\n",
    "# CNN Layers\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(50, return_sequences=True)(input_layer)\n",
    "\n",
    "# Attention Layer\n",
    "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
    "attention_output = Flatten()(attention_layer)\n",
    "\n",
    "# Merge CNN and LSTM outputs\n",
    "merged = tf.keras.layers.Concatenate()([flatten, attention_output])\n",
    "\n",
    "# Dense Layers\n",
    "dense1 = Dense(64, activation='relu')(merged)\n",
    "dropout1 = Dropout(0.2)(dense1)\n",
    "dense2 = Dense(32, activation='relu')(dropout1)\n",
    "output_layer = Dense(5)(dense2)  # Output 5 environmental variables\n",
    "\n",
    "# Build Model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Train the Model\n",
    "# ------------------------------- #\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Prepare Test Data for Prediction\n",
    "# ------------------------------- #\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\")\n",
    "\n",
    "# Convert Year, Month, Day to datetime\n",
    "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']])\n",
    "\n",
    "test_df = test_df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
    "\n",
    "# Merge with last known training data\n",
    "last_train_data = df[df['date'] <= test_df['date'].min()]\n",
    "test_df = test_df.merge(last_train_data, on='date', how='left')\n",
    "test_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Normalize test data\n",
    "scaled_test_data = scaler.transform(test_df.drop(columns=['date']))\n",
    "\n",
    "# Convert test data into sequences\n",
    "X_test_seq, _ = create_sequences(pd.DataFrame(scaled_test_data, columns=test_df.columns[1:]))\n",
    "\n",
    "# ------------------------------- #\n",
    "# Make Predictions\n",
    "# ------------------------------- #\n",
    "predictions = model.predict(X_test_seq)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "predicted_values = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Save predictions\n",
    "test_df[['Predicted_Temperature', 'Predicted_Radiation', 'Predicted_Rain', 'Predicted_WindSpeed', 'Predicted_WindDirection']] = predicted_values\n",
    "test_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a038d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.37837827 0.25       0.02420628 ... 0.13152401 0.78830084 0.68445559]\n",
      "  [0.29729649 0.649993   0.01543589 ... 0.17118998 0.46518106 0.64547147]\n",
      "  [0.37837827 1.         0.03017015 ... 0.29436326 0.51810585 0.67249359]\n",
      "  ...\n",
      "  [0.27026991 0.049987   0.02771444 ... 0.20250522 0.59610028 0.66474605]\n",
      "  [0.54053981 0.         0.03017015 ... 0.2045929  0.72980501 0.70763863]\n",
      "  [0.24324332 0.049987   0.0270128  ... 0.16075157 0.65181058 0.66027023]]\n",
      "\n",
      " [[0.29729649 0.649993   0.01543589 ... 0.17118998 0.46518106 0.64547147]\n",
      "  [0.37837827 1.         0.03017015 ... 0.29436326 0.51810585 0.67249359]\n",
      "  [0.29729649 0.049987   0.98666901 ... 0.16075157 0.65181058 0.66585943]\n",
      "  ...\n",
      "  [0.54053981 0.         0.03017015 ... 0.2045929  0.72980501 0.70763863]\n",
      "  [0.24324332 0.049987   0.0270128  ... 0.16075157 0.65181058 0.66027023]\n",
      "  [0.         0.299987   0.9887739  ... 0.16283925 0.46239554 0.73973196]]\n",
      "\n",
      " [[0.37837827 1.         0.03017015 ... 0.29436326 0.51810585 0.67249359]\n",
      "  [0.29729649 0.049987   0.98666901 ... 0.16075157 0.65181058 0.66585943]\n",
      "  [1.         0.09999    0.03473075 ... 0.39248434 0.46796657 0.77559587]\n",
      "  ...\n",
      "  [0.24324332 0.049987   0.0270128  ... 0.16075157 0.65181058 0.66027023]\n",
      "  [0.         0.299987   0.9887739  ... 0.16283925 0.46239554 0.73973196]\n",
      "  [0.24324332 0.399993   0.96562007 ... 0.02087683 0.24233983 0.68229962]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.24324332 0.049987   0.98316085 ... 0.19415449 0.22562674 0.69721981]\n",
      "  [0.27026991 0.049987   0.02490791 ... 0.13361169 0.22284123 0.6669706 ]\n",
      "  [0.54053981 0.         0.02525873 ... 0.31732777 0.28133705 0.72989912]\n",
      "  ...\n",
      "  [0.35135169 0.399993   0.00596387 ... 0.1691023  0.3091922  0.60728358]\n",
      "  [0.         0.299987   0.02350465 ... 0.21294363 0.22841226 0.66807957]\n",
      "  [0.02702659 0.199995   0.9842133  ... 0.21294363 0.22841226 0.68121851]]\n",
      "\n",
      " [[0.27026991 0.049987   0.02490791 ... 0.13361169 0.22284123 0.6669706 ]\n",
      "  [0.54053981 0.         0.02525873 ... 0.31732777 0.28133705 0.72989912]\n",
      "  [0.21621673 0.25       0.97684617 ... 0.1085595  0.27576602 0.65348864]\n",
      "  ...\n",
      "  [0.         0.299987   0.02350465 ... 0.21294363 0.22841226 0.66807957]\n",
      "  [0.02702659 0.199995   0.9842133  ... 0.21294363 0.22841226 0.68121851]\n",
      "  [0.37837827 0.25       0.01824241 ... 0.25469729 0.25626741 0.67687306]]\n",
      "\n",
      " [[0.54053981 0.         0.02525873 ... 0.31732777 0.28133705 0.72989912]\n",
      "  [0.21621673 0.25       0.97684617 ... 0.1085595  0.27576602 0.65348864]\n",
      "  [0.21621673 0.049987   0.02385546 ... 0.13152401 0.2005571  0.68980945]\n",
      "  ...\n",
      "  [0.02702659 0.199995   0.9842133  ... 0.21294363 0.22841226 0.68121851]\n",
      "  [0.37837827 0.25       0.01824241 ... 0.25469729 0.25626741 0.67687306]\n",
      "  [0.37837827 1.         0.0245571  ... 0.29227557 0.15041783 0.66474605]]]\n",
      "[[0.         0.299987   0.9887739  ... 0.16283925 0.46239554 0.73973196]\n",
      " [0.24324332 0.399993   0.96562007 ... 0.02087683 0.24233983 0.68229962]\n",
      " [0.24324332 0.09999    0.98701982 ... 0.1440501  0.59052925 0.71887958]\n",
      " ...\n",
      " [0.37837827 0.25       0.01824241 ... 0.25469729 0.25626741 0.67687306]\n",
      " [0.37837827 1.         0.0245571  ... 0.29227557 0.15041783 0.66474605]\n",
      " [0.43243144 0.399993   0.01403263 ... 0.23382046 0.30640669 0.62191119]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_14              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,600</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_15              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1724</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ flatten_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">110,400</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m12\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m2,368\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_14              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │          \u001b[38;5;34m12,600\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_15              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_7 (\u001b[38;5;33mAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_14 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ attention_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_7 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1724\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ flatten_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ flatten_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m110,400\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m165\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,789</span> (522.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m133,789\u001b[0m (522.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,789</span> (522.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,789\u001b[0m (522.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 12 and 5 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, functional_7_1/dense_27_1/BiasAdd)' with input shapes: [?,12], [?,5].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31368\\539031398.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;31m# Train the Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;31m# ------------------------------- #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;31m# Plot Training Loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\losses\\losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m   1677\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m     \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqueeze_or_expand_to_same_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1679\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 12 and 5 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, functional_7_1/dense_27_1/BiasAdd)' with input shapes: [?,12], [?,5]."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, Attention\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------- #\n",
    "# Load and Preprocess Training Data\n",
    "# ------------------------------- #\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\train.csv\")\n",
    "\n",
    "# Define the starting year (adjust this based on the dataset)\n",
    "base_year = 2010  # If Year 1 corresponds to 2016\n",
    "\n",
    "# Convert Year values\n",
    "df['Year'] = df['Year'] + base_year\n",
    "\n",
    "# Ensure Month and Day are correctly formatted\n",
    "df['Month'] = df['Month'].astype(str).str.zfill(2)\n",
    "df['Day'] = df['Day'].astype(str).str.zfill(2)\n",
    "\n",
    "# Convert to proper datetime format\n",
    "df['date'] = pd.to_datetime(df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
    "\n",
    "\n",
    "\n",
    "df1 = df[['ID', 'kingdom', 'Year', 'Month', 'Day']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df.drop(columns=['date']))\n",
    "\n",
    "# Convert to DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns[1:])\n",
    "\n",
    "# ------------------------------- #\n",
    "# Create Time Series Sequences\n",
    "# ------------------------------- #\n",
    "TIME_STEPS = 30   # Past 30 days as input\n",
    "PREDICT_HORIZON = 1  # Predicting 1 day ahead\n",
    "\"\"\"\n",
    "def create_sequences(data, time_steps=TIME_STEPS, predict_horizon=PREDICT_HORIZON):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps - predict_horizon):\n",
    "        X.append(data.iloc[i: i + time_steps].values)\n",
    "        y.append(data.iloc[i + time_steps + predict_horizon - 1].values)  # Predict all 5 variables\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "# Create sequences\n",
    "X, y = create_sequences(scaled_df)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "X = []\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# ------------------------------- #\n",
    "# Build CNN-LSTM-Attention Model\n",
    "# ------------------------------- #\n",
    "\n",
    "# Define model input\n",
    "input_layer = Input(shape=(TIME_STEPS, X_train.shape[2]))\n",
    "\n",
    "# CNN Layers\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(50, return_sequences=True)(input_layer)\n",
    "\n",
    "# Attention Layer\n",
    "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
    "attention_output = Flatten()(attention_layer)\n",
    "\n",
    "# Merge CNN and LSTM outputs\n",
    "merged = tf.keras.layers.Concatenate()([flatten, attention_output])\n",
    "\n",
    "# Dense Layers\n",
    "dense1 = Dense(64, activation='relu')(merged)\n",
    "dropout1 = Dropout(0.2)(dense1)\n",
    "dense2 = Dense(32, activation='relu')(dropout1)\n",
    "output_layer = Dense(5)(dense2)  # Predicting all 5 variables\n",
    "\n",
    "# Build Model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Train the Model\n",
    "# ------------------------------- #\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Prepare Test Data for Prediction\n",
    "# ------------------------------- #\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\test.csv\")\n",
    "\n",
    "# Convert Year to actual year (same base year as training data)\n",
    "test_df['Year'] = test_df['Year'] + base_year\n",
    "\n",
    "# Convert Year, Month, Day to datetime\n",
    "test_df['date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']].astype(str).agg('-'.join, axis=1))\n",
    "\n",
    "# Drop unnecessary columns\n",
    "test_df = test_df.drop(columns=['ID', 'kingdom', 'Year', 'Month', 'Day'])\n",
    "\n",
    "# Merge with last known training data (to get missing feature values)\n",
    "last_train_data = df[df['date'] <= test_df['date'].min()]  # Get last available data\n",
    "test_df = test_df.merge(last_train_data, on='date', how='left')\n",
    "\n",
    "# Fill missing values using forward fill\n",
    "test_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Normalize test data\n",
    "scaled_test_data = scaler.transform(test_df.drop(columns=['date']))\n",
    "\n",
    "# Convert test data into sequences\n",
    "X_test_seq, _ = create_sequences(pd.DataFrame(scaled_test_data, columns=test_df.columns[1:]))\n",
    "\n",
    "# ------------------------------- #\n",
    "# Make Predictions\n",
    "# ------------------------------- #\n",
    "predictions = model.predict(X_test_seq)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "predicted_values = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Assign predictions to test dataframe\n",
    "test_df[['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']] = predicted_values\n",
    "\n",
    "# Save predictions\n",
    "test_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef7871cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b1e1a29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "90281bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84d303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9469545a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc501a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37837827, 0.25      , 0.02420628, ..., 0.13152401, 0.78830084,\n",
       "        0.68445559],\n",
       "       [0.29729649, 0.649993  , 0.01543589, ..., 0.17118998, 0.46518106,\n",
       "        0.64547147],\n",
       "       [0.37837827, 1.        , 0.03017015, ..., 0.29436326, 0.51810585,\n",
       "        0.67249359],\n",
       "       ...,\n",
       "       [0.37837827, 1.        , 0.0245571 , ..., 0.29227557, 0.15041783,\n",
       "        0.66474605],\n",
       "       [0.43243144, 0.399993  , 0.01403263, ..., 0.23382046, 0.30640669,\n",
       "        0.62191119],\n",
       "       [0.29729649, 0.649993  , 0.00526223, ..., 0.14822547, 0.14763231,\n",
       "        0.62311307]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7fc79ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84960"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f334795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Atlantis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Avalon</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Camelot</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dorne</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84955</th>\n",
       "      <td>84956</td>\n",
       "      <td>Solstice</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84956</th>\n",
       "      <td>84957</td>\n",
       "      <td>Sunspear</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84957</th>\n",
       "      <td>84958</td>\n",
       "      <td>Utopia</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84958</th>\n",
       "      <td>84959</td>\n",
       "      <td>Valyria</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84959</th>\n",
       "      <td>84960</td>\n",
       "      <td>Winterfell</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84960 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID     kingdom  Year  Month  Day\n",
       "0          1     Arcadia     1      4    1\n",
       "1          2    Atlantis     1      4    1\n",
       "2          3      Avalon     1      4    1\n",
       "3          4     Camelot     1      4    1\n",
       "4          5       Dorne     1      4    1\n",
       "...      ...         ...   ...    ...  ...\n",
       "84955  84956    Solstice     8     12   31\n",
       "84956  84957    Sunspear     8     12   31\n",
       "84957  84958      Utopia     8     12   31\n",
       "84958  84959     Valyria     8     12   31\n",
       "84959  84960  Winterfell     8     12   31\n",
       "\n",
       "[84960 rows x 5 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[['ID', 'kingdom', 'Year', 'Month', 'Day']]\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf03307a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.280002</td>\n",
       "      <td>-35.729980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.979999</td>\n",
       "      <td>-37.630006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.580005</td>\n",
       "      <td>-37.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84955</th>\n",
       "      <td>22.979999</td>\n",
       "      <td>-37.329990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84956</th>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84957</th>\n",
       "      <td>24.280002</td>\n",
       "      <td>-35.729980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84958</th>\n",
       "      <td>24.479999</td>\n",
       "      <td>-36.929994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84959</th>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude  longitude\n",
       "0      24.280002 -37.229980\n",
       "1      23.979999 -36.429994\n",
       "2      24.280002 -35.729980\n",
       "3      23.979999 -37.630006\n",
       "4      26.580005 -37.530000\n",
       "...          ...        ...\n",
       "84955  22.979999 -37.329990\n",
       "84956  24.280002 -37.229980\n",
       "84957  24.280002 -35.729980\n",
       "84958  24.479999 -36.929994\n",
       "84959  23.979999 -36.429994\n",
       "\n",
       "[84960 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"latitude\", \"longitude\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4524b107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Feels_Like_Temperature</th>\n",
       "      <th>Temperature_Range</th>\n",
       "      <th>Feels_Like_Temperature_Range</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Rain_Amount</th>\n",
       "      <th>Rain_Duration</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Wind_Direction</th>\n",
       "      <th>Evapotranspiration</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.040557</td>\n",
       "      <td>0.536913</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.718320</td>\n",
       "      <td>0.133707</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.131524</td>\n",
       "      <td>0.788301</td>\n",
       "      <td>0.684456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.297296</td>\n",
       "      <td>0.649993</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>0.027840</td>\n",
       "      <td>0.469799</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.694166</td>\n",
       "      <td>0.025679</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.171190</td>\n",
       "      <td>0.465181</td>\n",
       "      <td>0.645471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.378378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>0.044338</td>\n",
       "      <td>0.295302</td>\n",
       "      <td>0.315152</td>\n",
       "      <td>0.668153</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.294363</td>\n",
       "      <td>0.518106</td>\n",
       "      <td>0.672494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.297296</td>\n",
       "      <td>0.049987</td>\n",
       "      <td>0.986669</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.335570</td>\n",
       "      <td>0.448485</td>\n",
       "      <td>0.681531</td>\n",
       "      <td>0.150236</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.160752</td>\n",
       "      <td>0.651811</td>\n",
       "      <td>0.665859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099990</td>\n",
       "      <td>0.034731</td>\n",
       "      <td>0.048462</td>\n",
       "      <td>0.288591</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.753252</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.392484</td>\n",
       "      <td>0.467967</td>\n",
       "      <td>0.775596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84955</th>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.199995</td>\n",
       "      <td>0.984213</td>\n",
       "      <td>0.979034</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.696024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212944</td>\n",
       "      <td>0.228412</td>\n",
       "      <td>0.681219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84956</th>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>0.024403</td>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.670011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254697</td>\n",
       "      <td>0.256267</td>\n",
       "      <td>0.676873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84957</th>\n",
       "      <td>0.378378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024557</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.234899</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.614270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292276</td>\n",
       "      <td>0.150418</td>\n",
       "      <td>0.664746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84958</th>\n",
       "      <td>0.432431</td>\n",
       "      <td>0.399993</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>0.020278</td>\n",
       "      <td>0.624161</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.619472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233820</td>\n",
       "      <td>0.306407</td>\n",
       "      <td>0.621911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84959</th>\n",
       "      <td>0.297296</td>\n",
       "      <td>0.649993</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.530201</td>\n",
       "      <td>0.624242</td>\n",
       "      <td>0.673356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148225</td>\n",
       "      <td>0.147632</td>\n",
       "      <td>0.623113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84960 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  Avg_Temperature  Avg_Feels_Like_Temperature  \\\n",
       "0       0.378378         0.250000                    0.024206   \n",
       "1       0.297296         0.649993                    0.015436   \n",
       "2       0.378378         1.000000                    0.030170   \n",
       "3       0.297296         0.049987                    0.986669   \n",
       "4       1.000000         0.099990                    0.034731   \n",
       "...          ...              ...                         ...   \n",
       "84955   0.027027         0.199995                    0.984213   \n",
       "84956   0.378378         0.250000                    0.018242   \n",
       "84957   0.378378         1.000000                    0.024557   \n",
       "84958   0.432431         0.399993                    0.014033   \n",
       "84959   0.297296         0.649993                    0.005262   \n",
       "\n",
       "       Temperature_Range  Feels_Like_Temperature_Range  Radiation  \\\n",
       "0               0.040557                      0.536913   0.575758   \n",
       "1               0.027840                      0.469799   0.515152   \n",
       "2               0.044338                      0.295302   0.315152   \n",
       "3               0.984877                      0.335570   0.448485   \n",
       "4               0.048462                      0.288591   0.509091   \n",
       "...                  ...                           ...        ...   \n",
       "84955           0.979034                      0.416107   0.527273   \n",
       "84956           0.024403                      0.590604   0.606061   \n",
       "84957           0.032308                      0.234899   0.181818   \n",
       "84958           0.020278                      0.624161   0.618182   \n",
       "84959           0.009624                      0.530201   0.624242   \n",
       "\n",
       "       Rain_Amount  Rain_Duration  Wind_Speed  Wind_Direction  \\\n",
       "0         0.718320       0.133707    0.666667        0.131524   \n",
       "1         0.694166       0.025679    0.375000        0.171190   \n",
       "2         0.668153       0.007084    0.500000        0.294363   \n",
       "3         0.681531       0.150236    0.666667        0.160752   \n",
       "4         0.753252       0.005313    0.291667        0.392484   \n",
       "...            ...            ...         ...             ...   \n",
       "84955     0.696024       0.000000    0.000000        0.212944   \n",
       "84956     0.670011       0.000000    0.000000        0.254697   \n",
       "84957     0.614270       0.000000    0.000000        0.292276   \n",
       "84958     0.619472       0.000000    0.000000        0.233820   \n",
       "84959     0.673356       0.000000    0.000000        0.148225   \n",
       "\n",
       "       Evapotranspiration      date  \n",
       "0                0.788301  0.684456  \n",
       "1                0.465181  0.645471  \n",
       "2                0.518106  0.672494  \n",
       "3                0.651811  0.665859  \n",
       "4                0.467967  0.775596  \n",
       "...                   ...       ...  \n",
       "84955            0.228412  0.681219  \n",
       "84956            0.256267  0.676873  \n",
       "84957            0.150418  0.664746  \n",
       "84958            0.306407  0.621911  \n",
       "84959            0.147632  0.623113  \n",
       "\n",
       "[84960 rows x 12 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd446c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67943"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93af8890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kingdom</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>ID</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Feels_Like_Temperature</th>\n",
       "      <th>Temperature_Range</th>\n",
       "      <th>Feels_Like_Temperature_Range</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Rain_Amount</th>\n",
       "      <th>Rain_Duration</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Wind_Direction</th>\n",
       "      <th>Evapotranspiration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>25.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>22.52</td>\n",
       "      <td>58.89</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>283.0</td>\n",
       "      <td>1.648659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>25.8</td>\n",
       "      <td>31.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>24.29</td>\n",
       "      <td>16.77</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1.713798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.33</td>\n",
       "      <td>8.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1.682688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>26.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.35</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>121.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>27.9</td>\n",
       "      <td>32.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>26.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.851599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>84811.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>24.8</td>\n",
       "      <td>29.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.82</td>\n",
       "      <td>1.30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1.558145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>84841.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>25.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>19.95</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.541159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>84871.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>22.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.693779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>84901.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>23.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.710188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>84931.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>23.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>21.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.635106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2832 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      kingdom  Year  Month  Day       ID   latitude  longitude  \\\n",
       "0     Arcadia     1      4    1      1.0  24.280002  -37.22998   \n",
       "1     Arcadia     1      4    2     31.0  24.280002  -37.22998   \n",
       "2     Arcadia     1      4    3     61.0  24.280002  -37.22998   \n",
       "3     Arcadia     1      4    4     91.0  24.280002  -37.22998   \n",
       "4     Arcadia     1      4    5    121.0  24.280002  -37.22998   \n",
       "...       ...   ...    ...  ...      ...        ...        ...   \n",
       "2827  Arcadia     8     12   27  84811.0  24.280002  -37.22998   \n",
       "2828  Arcadia     8     12   28  84841.0  24.280002  -37.22998   \n",
       "2829  Arcadia     8     12   29  84871.0  24.280002  -37.22998   \n",
       "2830  Arcadia     8     12   30  84901.0  24.280002  -37.22998   \n",
       "2831  Arcadia     8     12   31  84931.0  24.280002  -37.22998   \n",
       "\n",
       "      Avg_Temperature  Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
       "0                25.5                        30.5                8.5   \n",
       "1                25.8                        31.1                8.7   \n",
       "2                26.0                        30.9                7.5   \n",
       "3                26.7                        31.6                8.1   \n",
       "4                27.9                        32.8               10.1   \n",
       "...               ...                         ...                ...   \n",
       "2827             24.8                        29.4                8.0   \n",
       "2828             25.2                        29.4                8.1   \n",
       "2829             25.0                        27.9                8.5   \n",
       "2830             24.0                        25.8                9.0   \n",
       "2831             23.8                        25.8                9.3   \n",
       "\n",
       "      Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
       "0                             10.3      22.52        58.89           16.0   \n",
       "1                             11.4      24.29        16.77            7.0   \n",
       "2                             10.0      23.33         8.19            4.0   \n",
       "3                             10.0      23.35         0.91            3.0   \n",
       "4                             12.8      26.85         0.00            0.0   \n",
       "...                            ...        ...          ...            ...   \n",
       "2827                          10.0      20.82         1.30            8.0   \n",
       "2828                           8.7      19.95         0.65            3.0   \n",
       "2829                           8.9      22.97         0.00            0.0   \n",
       "2830                          10.2      23.29         0.00            0.0   \n",
       "2831                          10.8      21.22         0.00            0.0   \n",
       "\n",
       "      Wind_Speed  Wind_Direction  Evapotranspiration  \n",
       "0            8.6           283.0            1.648659  \n",
       "1            9.4           257.0            1.713798  \n",
       "2            9.4           252.0            1.682688  \n",
       "3           10.4           247.0            1.704748  \n",
       "4           10.6           256.0            1.851599  \n",
       "...          ...             ...                 ...  \n",
       "2827         5.2           114.0            1.558145  \n",
       "2828        10.0            96.0            1.541159  \n",
       "2829        15.5           102.0            1.693779  \n",
       "2830        16.1            97.0            1.710188  \n",
       "2831        14.5            92.0            1.635106  \n",
       "\n",
       "[2832 rows x 17 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\cleaned_data.csv\")\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\cleaned_data.csv\")\n",
    "\n",
    "df_avg = df.groupby(['kingdom', 'Year', 'Month', 'Day'], as_index=False).mean(numeric_only=True)\n",
    "\n",
    "\n",
    "\n",
    "df_avg[df_avg[\"kingdom\"]==\"Arcadia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5e68f626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Feels_Like_Temperature</th>\n",
       "      <th>Temperature_Range</th>\n",
       "      <th>Feels_Like_Temperature_Range</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Rain_Amount</th>\n",
       "      <th>Rain_Duration</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Wind_Direction</th>\n",
       "      <th>Evapotranspiration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "      <td>25.5</td>\n",
       "      <td>30.50</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>22.52</td>\n",
       "      <td>58.89</td>\n",
       "      <td>16</td>\n",
       "      <td>8.6</td>\n",
       "      <td>283</td>\n",
       "      <td>1.648659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Atlantis</td>\n",
       "      <td>22.979999</td>\n",
       "      <td>-37.329990</td>\n",
       "      <td>26.5</td>\n",
       "      <td>305.15</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>22.73</td>\n",
       "      <td>11.83</td>\n",
       "      <td>12</td>\n",
       "      <td>15.8</td>\n",
       "      <td>161</td>\n",
       "      <td>1.583094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Avalon</td>\n",
       "      <td>22.880000</td>\n",
       "      <td>-37.130006</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>22.73</td>\n",
       "      <td>11.83</td>\n",
       "      <td>12</td>\n",
       "      <td>15.8</td>\n",
       "      <td>161</td>\n",
       "      <td>1.593309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Camelot</td>\n",
       "      <td>24.180003</td>\n",
       "      <td>-36.929994</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.40</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>22.67</td>\n",
       "      <td>75.27</td>\n",
       "      <td>16</td>\n",
       "      <td>6.4</td>\n",
       "      <td>346</td>\n",
       "      <td>1.638997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dorne</td>\n",
       "      <td>25.780002</td>\n",
       "      <td>-37.530000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>32.80</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>22.35</td>\n",
       "      <td>4.81</td>\n",
       "      <td>8</td>\n",
       "      <td>16.7</td>\n",
       "      <td>185</td>\n",
       "      <td>1.719189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84955</th>\n",
       "      <td>84956</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Solstice</td>\n",
       "      <td>25.479998</td>\n",
       "      <td>-36.329990</td>\n",
       "      <td>25.6</td>\n",
       "      <td>28.60</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>19.41</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>90</td>\n",
       "      <td>1.562346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84956</th>\n",
       "      <td>84957</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Sunspear</td>\n",
       "      <td>26.580005</td>\n",
       "      <td>-37.530000</td>\n",
       "      <td>25.8</td>\n",
       "      <td>28.90</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>20.98</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>16.3</td>\n",
       "      <td>91</td>\n",
       "      <td>1.607436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84957</th>\n",
       "      <td>84958</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Utopia</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-37.630006</td>\n",
       "      <td>25.6</td>\n",
       "      <td>301.65</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>71</td>\n",
       "      <td>1.710188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84958</th>\n",
       "      <td>84959</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Valyria</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-35.729980</td>\n",
       "      <td>25.6</td>\n",
       "      <td>28.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>19.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>54</td>\n",
       "      <td>1.613430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84959</th>\n",
       "      <td>84960</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Winterfell</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "      <td>20.1</td>\n",
       "      <td>21.50</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>21.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>53</td>\n",
       "      <td>1.539015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84960 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Year  Month  Day     kingdom   latitude  longitude  \\\n",
       "0          1     1      4    1     Arcadia  24.280002 -37.229980   \n",
       "1          2     1      4    1    Atlantis  22.979999 -37.329990   \n",
       "2          3     1      4    1      Avalon  22.880000 -37.130006   \n",
       "3          4     1      4    1     Camelot  24.180003 -36.929994   \n",
       "4          5     1      4    1       Dorne  25.780002 -37.530000   \n",
       "...      ...   ...    ...  ...         ...        ...        ...   \n",
       "84955  84956     8     12   31    Solstice  25.479998 -36.329990   \n",
       "84956  84957     8     12   31    Sunspear  26.580005 -37.530000   \n",
       "84957  84958     8     12   31      Utopia  23.979999 -37.630006   \n",
       "84958  84959     8     12   31     Valyria  24.280002 -35.729980   \n",
       "84959  84960     8     12   31  Winterfell  23.979999 -36.429994   \n",
       "\n",
       "       Avg_Temperature  Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
       "0                 25.5                       30.50                8.5   \n",
       "1                 26.5                      305.15                5.9   \n",
       "2                 26.3                       31.50                5.2   \n",
       "3                 24.0                       28.40                8.2   \n",
       "4                 28.0                       32.80                5.7   \n",
       "...                ...                         ...                ...   \n",
       "84955             25.6                       28.60                3.4   \n",
       "84956             25.8                       28.90                2.8   \n",
       "84957             25.6                      301.65                7.6   \n",
       "84958             25.6                       28.10                4.0   \n",
       "84959             20.1                       21.50                8.4   \n",
       "\n",
       "       Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
       "0                              10.3      22.52        58.89             16   \n",
       "1                               8.2      22.73        11.83             12   \n",
       "2                               6.4      22.73        11.83             12   \n",
       "3                              10.7      22.67        75.27             16   \n",
       "4                              10.2      22.35         4.81              8   \n",
       "...                             ...        ...          ...            ...   \n",
       "84955                           3.5      19.41         0.13              1   \n",
       "84956                           3.7      20.98         0.26              2   \n",
       "84957                           9.2      22.67         0.00              0   \n",
       "84958                           3.8      19.72         0.00              0   \n",
       "84959                          11.1      21.31         0.00              0   \n",
       "\n",
       "       Wind_Speed  Wind_Direction  Evapotranspiration  \n",
       "0             8.6             283            1.648659  \n",
       "1            15.8             161            1.583094  \n",
       "2            15.8             161            1.593309  \n",
       "3             6.4             346            1.638997  \n",
       "4            16.7             185            1.719189  \n",
       "...           ...             ...                 ...  \n",
       "84955        14.8              90            1.562346  \n",
       "84956        16.3              91            1.607436  \n",
       "84957        12.6              71            1.710188  \n",
       "84958        16.3              54            1.613430  \n",
       "84959         9.4              53            1.539015  \n",
       "\n",
       "[84960 rows x 17 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "293a1369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dc1edc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Feels_Like_Temperature</th>\n",
       "      <th>Temperature_Range</th>\n",
       "      <th>Feels_Like_Temperature_Range</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Rain_Amount</th>\n",
       "      <th>Rain_Duration</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Wind_Direction</th>\n",
       "      <th>Evapotranspiration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>25.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>22.52</td>\n",
       "      <td>58.89</td>\n",
       "      <td>16</td>\n",
       "      <td>8.6</td>\n",
       "      <td>283</td>\n",
       "      <td>1.648659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>25.8</td>\n",
       "      <td>31.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>24.29</td>\n",
       "      <td>16.77</td>\n",
       "      <td>7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>257</td>\n",
       "      <td>1.713798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.33</td>\n",
       "      <td>8.19</td>\n",
       "      <td>4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>252</td>\n",
       "      <td>1.682688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>26.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.35</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>247</td>\n",
       "      <td>1.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>27.9</td>\n",
       "      <td>32.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>26.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>256</td>\n",
       "      <td>1.851599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84810</th>\n",
       "      <td>84811</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>24.8</td>\n",
       "      <td>29.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.82</td>\n",
       "      <td>1.30</td>\n",
       "      <td>8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>114</td>\n",
       "      <td>1.558145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84840</th>\n",
       "      <td>84841</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>25.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>19.95</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.541159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84870</th>\n",
       "      <td>84871</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>22.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>102</td>\n",
       "      <td>1.693779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84900</th>\n",
       "      <td>84901</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>23.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>97</td>\n",
       "      <td>1.710188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84930</th>\n",
       "      <td>84931</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.22998</td>\n",
       "      <td>23.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>21.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>92</td>\n",
       "      <td>1.635106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2832 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Year  Month  Day  kingdom   latitude  longitude  \\\n",
       "0          1     1      4    1  Arcadia  24.280002  -37.22998   \n",
       "30        31     1      4    2  Arcadia  24.280002  -37.22998   \n",
       "60        61     1      4    3  Arcadia  24.280002  -37.22998   \n",
       "90        91     1      4    4  Arcadia  24.280002  -37.22998   \n",
       "120      121     1      4    5  Arcadia  24.280002  -37.22998   \n",
       "...      ...   ...    ...  ...      ...        ...        ...   \n",
       "84810  84811     8     12   27  Arcadia  24.280002  -37.22998   \n",
       "84840  84841     8     12   28  Arcadia  24.280002  -37.22998   \n",
       "84870  84871     8     12   29  Arcadia  24.280002  -37.22998   \n",
       "84900  84901     8     12   30  Arcadia  24.280002  -37.22998   \n",
       "84930  84931     8     12   31  Arcadia  24.280002  -37.22998   \n",
       "\n",
       "       Avg_Temperature  Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
       "0                 25.5                        30.5                8.5   \n",
       "30                25.8                        31.1                8.7   \n",
       "60                26.0                        30.9                7.5   \n",
       "90                26.7                        31.6                8.1   \n",
       "120               27.9                        32.8               10.1   \n",
       "...                ...                         ...                ...   \n",
       "84810             24.8                        29.4                8.0   \n",
       "84840             25.2                        29.4                8.1   \n",
       "84870             25.0                        27.9                8.5   \n",
       "84900             24.0                        25.8                9.0   \n",
       "84930             23.8                        25.8                9.3   \n",
       "\n",
       "       Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
       "0                              10.3      22.52        58.89             16   \n",
       "30                             11.4      24.29        16.77              7   \n",
       "60                             10.0      23.33         8.19              4   \n",
       "90                             10.0      23.35         0.91              3   \n",
       "120                            12.8      26.85         0.00              0   \n",
       "...                             ...        ...          ...            ...   \n",
       "84810                          10.0      20.82         1.30              8   \n",
       "84840                           8.7      19.95         0.65              3   \n",
       "84870                           8.9      22.97         0.00              0   \n",
       "84900                          10.2      23.29         0.00              0   \n",
       "84930                          10.8      21.22         0.00              0   \n",
       "\n",
       "       Wind_Speed  Wind_Direction  Evapotranspiration  \n",
       "0             8.6             283            1.648659  \n",
       "30            9.4             257            1.713798  \n",
       "60            9.4             252            1.682688  \n",
       "90           10.4             247            1.704748  \n",
       "120          10.6             256            1.851599  \n",
       "...           ...             ...                 ...  \n",
       "84810         5.2             114            1.558145  \n",
       "84840        10.0              96            1.541159  \n",
       "84870        15.5             102            1.693779  \n",
       "84900        16.1              97            1.710188  \n",
       "84930        14.5              92            1.635106  \n",
       "\n",
       "[2832 rows x 17 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"kingdom\"]== \"Arcadia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "21850680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Feels_Like_Temperature</th>\n",
       "      <th>Temperature_Range</th>\n",
       "      <th>Feels_Like_Temperature_Range</th>\n",
       "      <th>...</th>\n",
       "      <th>kingdom_Rapture</th>\n",
       "      <th>kingdom_Rivendell</th>\n",
       "      <th>kingdom_Serenity</th>\n",
       "      <th>kingdom_Shangri-La</th>\n",
       "      <th>kingdom_Solara</th>\n",
       "      <th>kingdom_Solstice</th>\n",
       "      <th>kingdom_Sunspear</th>\n",
       "      <th>kingdom_Utopia</th>\n",
       "      <th>kingdom_Valyria</th>\n",
       "      <th>kingdom_Winterfell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "      <td>25.50</td>\n",
       "      <td>30.50</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22.979999</td>\n",
       "      <td>-37.329990</td>\n",
       "      <td>299.65</td>\n",
       "      <td>305.15</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22.880000</td>\n",
       "      <td>-37.130006</td>\n",
       "      <td>26.30</td>\n",
       "      <td>31.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24.180003</td>\n",
       "      <td>-36.929994</td>\n",
       "      <td>24.00</td>\n",
       "      <td>28.40</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25.780002</td>\n",
       "      <td>-37.530000</td>\n",
       "      <td>28.00</td>\n",
       "      <td>32.80</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84955</th>\n",
       "      <td>84956</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>25.479998</td>\n",
       "      <td>-36.329990</td>\n",
       "      <td>25.60</td>\n",
       "      <td>28.60</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84956</th>\n",
       "      <td>84957</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>26.580005</td>\n",
       "      <td>-37.530000</td>\n",
       "      <td>25.80</td>\n",
       "      <td>28.90</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84957</th>\n",
       "      <td>84958</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-37.630006</td>\n",
       "      <td>298.75</td>\n",
       "      <td>301.65</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84958</th>\n",
       "      <td>84959</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-35.729980</td>\n",
       "      <td>25.60</td>\n",
       "      <td>28.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84959</th>\n",
       "      <td>84960</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "      <td>20.10</td>\n",
       "      <td>21.50</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84960 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Year  Month  Day   latitude  longitude  Avg_Temperature  \\\n",
       "0          1     1      4    1  24.280002 -37.229980            25.50   \n",
       "1          2     1      4    1  22.979999 -37.329990           299.65   \n",
       "2          3     1      4    1  22.880000 -37.130006            26.30   \n",
       "3          4     1      4    1  24.180003 -36.929994            24.00   \n",
       "4          5     1      4    1  25.780002 -37.530000            28.00   \n",
       "...      ...   ...    ...  ...        ...        ...              ...   \n",
       "84955  84956     8     12   31  25.479998 -36.329990            25.60   \n",
       "84956  84957     8     12   31  26.580005 -37.530000            25.80   \n",
       "84957  84958     8     12   31  23.979999 -37.630006           298.75   \n",
       "84958  84959     8     12   31  24.280002 -35.729980            25.60   \n",
       "84959  84960     8     12   31  23.979999 -36.429994            20.10   \n",
       "\n",
       "       Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
       "0                           30.50                8.5   \n",
       "1                          305.15                5.9   \n",
       "2                           31.50                5.2   \n",
       "3                           28.40                8.2   \n",
       "4                           32.80                5.7   \n",
       "...                           ...                ...   \n",
       "84955                       28.60                3.4   \n",
       "84956                       28.90                2.8   \n",
       "84957                      301.65                7.6   \n",
       "84958                       28.10                4.0   \n",
       "84959                       21.50                8.4   \n",
       "\n",
       "       Feels_Like_Temperature_Range  ...  kingdom_Rapture  kingdom_Rivendell  \\\n",
       "0                              10.3  ...                0                  0   \n",
       "1                               8.2  ...                0                  0   \n",
       "2                               6.4  ...                0                  0   \n",
       "3                              10.7  ...                0                  0   \n",
       "4                              10.2  ...                0                  0   \n",
       "...                             ...  ...              ...                ...   \n",
       "84955                           3.5  ...                0                  0   \n",
       "84956                           3.7  ...                0                  0   \n",
       "84957                           9.2  ...                0                  0   \n",
       "84958                           3.8  ...                0                  0   \n",
       "84959                          11.1  ...                0                  0   \n",
       "\n",
       "       kingdom_Serenity  kingdom_Shangri-La  kingdom_Solara  kingdom_Solstice  \\\n",
       "0                     0                   0               0                 0   \n",
       "1                     0                   0               0                 0   \n",
       "2                     0                   0               0                 0   \n",
       "3                     0                   0               0                 0   \n",
       "4                     0                   0               0                 0   \n",
       "...                 ...                 ...             ...               ...   \n",
       "84955                 0                   0               0                 1   \n",
       "84956                 0                   0               0                 0   \n",
       "84957                 0                   0               0                 0   \n",
       "84958                 0                   0               0                 0   \n",
       "84959                 0                   0               0                 0   \n",
       "\n",
       "       kingdom_Sunspear  kingdom_Utopia  kingdom_Valyria  kingdom_Winterfell  \n",
       "0                     0               0                0                   0  \n",
       "1                     0               0                0                   0  \n",
       "2                     0               0                0                   0  \n",
       "3                     0               0                0                   0  \n",
       "4                     0               0                0                   0  \n",
       "...                 ...             ...              ...                 ...  \n",
       "84955                 0               0                0                   0  \n",
       "84956                 1               0                0                   0  \n",
       "84957                 0               1                0                   0  \n",
       "84958                 0               0                1                   0  \n",
       "84959                 0               0                0                   1  \n",
       "\n",
       "[84960 rows x 45 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['kingdom'], drop_first=True)  # One-hot encoding\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0eeacc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[['Year', 'Month', 'Day']] = scaler.fit_transform(df[['Year', 'Month', 'Day']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a995cbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Feels_Like_Temperature</th>\n",
       "      <th>Temperature_Range</th>\n",
       "      <th>Feels_Like_Temperature_Range</th>\n",
       "      <th>...</th>\n",
       "      <th>kingdom_Rapture</th>\n",
       "      <th>kingdom_Rivendell</th>\n",
       "      <th>kingdom_Serenity</th>\n",
       "      <th>kingdom_Shangri-La</th>\n",
       "      <th>kingdom_Solara</th>\n",
       "      <th>kingdom_Solstice</th>\n",
       "      <th>kingdom_Sunspear</th>\n",
       "      <th>kingdom_Utopia</th>\n",
       "      <th>kingdom_Valyria</th>\n",
       "      <th>kingdom_Winterfell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "      <td>25.50</td>\n",
       "      <td>30.50</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.979999</td>\n",
       "      <td>-37.329990</td>\n",
       "      <td>299.65</td>\n",
       "      <td>305.15</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.880000</td>\n",
       "      <td>-37.130006</td>\n",
       "      <td>26.30</td>\n",
       "      <td>31.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.180003</td>\n",
       "      <td>-36.929994</td>\n",
       "      <td>24.00</td>\n",
       "      <td>28.40</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.780002</td>\n",
       "      <td>-37.530000</td>\n",
       "      <td>28.00</td>\n",
       "      <td>32.80</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84955</th>\n",
       "      <td>84956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.479998</td>\n",
       "      <td>-36.329990</td>\n",
       "      <td>25.60</td>\n",
       "      <td>28.60</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84956</th>\n",
       "      <td>84957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.580005</td>\n",
       "      <td>-37.530000</td>\n",
       "      <td>25.80</td>\n",
       "      <td>28.90</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84957</th>\n",
       "      <td>84958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-37.630006</td>\n",
       "      <td>298.75</td>\n",
       "      <td>301.65</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84958</th>\n",
       "      <td>84959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-35.729980</td>\n",
       "      <td>25.60</td>\n",
       "      <td>28.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84959</th>\n",
       "      <td>84960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "      <td>20.10</td>\n",
       "      <td>21.50</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84960 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Year     Month  Day   latitude  longitude  Avg_Temperature  \\\n",
       "0          1   0.0  0.272727  0.0  24.280002 -37.229980            25.50   \n",
       "1          2   0.0  0.272727  0.0  22.979999 -37.329990           299.65   \n",
       "2          3   0.0  0.272727  0.0  22.880000 -37.130006            26.30   \n",
       "3          4   0.0  0.272727  0.0  24.180003 -36.929994            24.00   \n",
       "4          5   0.0  0.272727  0.0  25.780002 -37.530000            28.00   \n",
       "...      ...   ...       ...  ...        ...        ...              ...   \n",
       "84955  84956   1.0  1.000000  1.0  25.479998 -36.329990            25.60   \n",
       "84956  84957   1.0  1.000000  1.0  26.580005 -37.530000            25.80   \n",
       "84957  84958   1.0  1.000000  1.0  23.979999 -37.630006           298.75   \n",
       "84958  84959   1.0  1.000000  1.0  24.280002 -35.729980            25.60   \n",
       "84959  84960   1.0  1.000000  1.0  23.979999 -36.429994            20.10   \n",
       "\n",
       "       Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
       "0                           30.50                8.5   \n",
       "1                          305.15                5.9   \n",
       "2                           31.50                5.2   \n",
       "3                           28.40                8.2   \n",
       "4                           32.80                5.7   \n",
       "...                           ...                ...   \n",
       "84955                       28.60                3.4   \n",
       "84956                       28.90                2.8   \n",
       "84957                      301.65                7.6   \n",
       "84958                       28.10                4.0   \n",
       "84959                       21.50                8.4   \n",
       "\n",
       "       Feels_Like_Temperature_Range  ...  kingdom_Rapture  kingdom_Rivendell  \\\n",
       "0                              10.3  ...                0                  0   \n",
       "1                               8.2  ...                0                  0   \n",
       "2                               6.4  ...                0                  0   \n",
       "3                              10.7  ...                0                  0   \n",
       "4                              10.2  ...                0                  0   \n",
       "...                             ...  ...              ...                ...   \n",
       "84955                           3.5  ...                0                  0   \n",
       "84956                           3.7  ...                0                  0   \n",
       "84957                           9.2  ...                0                  0   \n",
       "84958                           3.8  ...                0                  0   \n",
       "84959                          11.1  ...                0                  0   \n",
       "\n",
       "       kingdom_Serenity  kingdom_Shangri-La  kingdom_Solara  kingdom_Solstice  \\\n",
       "0                     0                   0               0                 0   \n",
       "1                     0                   0               0                 0   \n",
       "2                     0                   0               0                 0   \n",
       "3                     0                   0               0                 0   \n",
       "4                     0                   0               0                 0   \n",
       "...                 ...                 ...             ...               ...   \n",
       "84955                 0                   0               0                 1   \n",
       "84956                 0                   0               0                 0   \n",
       "84957                 0                   0               0                 0   \n",
       "84958                 0                   0               0                 0   \n",
       "84959                 0                   0               0                 0   \n",
       "\n",
       "       kingdom_Sunspear  kingdom_Utopia  kingdom_Valyria  kingdom_Winterfell  \n",
       "0                     0               0                0                   0  \n",
       "1                     0               0                0                   0  \n",
       "2                     0               0                0                   0  \n",
       "3                     0               0                0                   0  \n",
       "4                     0               0                0                   0  \n",
       "...                 ...             ...              ...                 ...  \n",
       "84955                 0               0                0                   0  \n",
       "84956                 1               0                0                   0  \n",
       "84957                 0               1                0                   0  \n",
       "84958                 0               0                1                   0  \n",
       "84959                 0               0                0                   1  \n",
       "\n",
       "[84960 rows x 45 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "da8250bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Year', 'Month', 'Day'] + [col for col in df.columns if 'Kingdom_' in col]].values\n",
    "Y = df[['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "340083b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84960"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a5a77f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.27272727, 0.        ])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "26193d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.27272727, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.27272727, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.27272727, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 1.        , 1.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "331229fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  Year  Month  Day     kingdom   latitude  longitude  \\\n",
      "0          1     1      4    1     Arcadia  24.280002 -37.229980   \n",
      "30        31     1      4    2     Arcadia  24.280002 -37.229980   \n",
      "60        61     1      4    3     Arcadia  24.280002 -37.229980   \n",
      "90        91     1      4    4     Arcadia  24.280002 -37.229980   \n",
      "120      121     1      4    5     Arcadia  24.280002 -37.229980   \n",
      "...      ...   ...    ...  ...         ...        ...        ...   \n",
      "84839  84840     8     12   27  Winterfell  23.979999 -36.429994   \n",
      "84869  84870     8     12   28  Winterfell  23.979999 -36.429994   \n",
      "84899  84900     8     12   29  Winterfell  23.979999 -36.429994   \n",
      "84929  84930     8     12   30  Winterfell  23.979999 -36.429994   \n",
      "84959  84960     8     12   31  Winterfell  23.979999 -36.429994   \n",
      "\n",
      "       Avg_Temperature  Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
      "0                 25.5                        30.5                8.5   \n",
      "30                25.8                        31.1                8.7   \n",
      "60                26.0                        30.9                7.5   \n",
      "90                26.7                        31.6                8.1   \n",
      "120               27.9                        32.8               10.1   \n",
      "...                ...                         ...                ...   \n",
      "84839             22.4                        25.5                7.6   \n",
      "84869             21.9                        25.0                5.6   \n",
      "84899             21.8                        24.0                6.4   \n",
      "84929             20.3                        21.8                8.1   \n",
      "84959             20.1                        21.5                8.4   \n",
      "\n",
      "       Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
      "0                              10.3      22.52        58.89             16   \n",
      "30                             11.4      24.29        16.77              7   \n",
      "60                             10.0      23.33         8.19              4   \n",
      "90                             10.0      23.35         0.91              3   \n",
      "120                            12.8      26.85         0.00              0   \n",
      "...                             ...        ...          ...            ...   \n",
      "84839                           8.8      22.18         0.26              2   \n",
      "84869                           7.1      18.89         3.51              9   \n",
      "84899                           7.3      23.23         0.00              0   \n",
      "84929                          10.8      23.35         0.00              0   \n",
      "84959                          11.1      21.31         0.00              0   \n",
      "\n",
      "       Wind_Speed  Wind_Direction  Evapotranspiration  \n",
      "0             8.6             283            1.648659  \n",
      "30            9.4             257            1.713798  \n",
      "60            9.4             252            1.682688  \n",
      "90           10.4             247            1.704748  \n",
      "120          10.6             256            1.851599  \n",
      "...           ...             ...                 ...  \n",
      "84839         8.7             142            1.578979  \n",
      "84869        10.5              81            1.415853  \n",
      "84899        12.6              76            1.601406  \n",
      "84929        10.7              66            1.587192  \n",
      "84959         9.4              53            1.539015  \n",
      "\n",
      "[84960 rows x 17 columns]\n",
      "(84930, 30, 32)\n",
      "(84930, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_18              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,600</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_19              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1724</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ flatten_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">110,400</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │ dense_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m6,208\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_18              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │          \u001b[38;5;34m16,600\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_19              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ conv1d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_9 (\u001b[38;5;33mAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_18 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_19 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ attention_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_9 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1724\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ flatten_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ flatten_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m110,400\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m165\u001b[0m │ dense_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,629</span> (553.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m141,629\u001b[0m (553.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,629</span> (553.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m141,629\u001b[0m (553.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 10 and 5 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, functional_9_1/dense_33_1/BiasAdd)' with input shapes: [?,10], [?,5].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31368\\56482648.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# Train the Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;31m# ------------------------------- #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;31m# Plot Training Loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\losses\\losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m   1677\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m     \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqueeze_or_expand_to_same_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1679\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 10 and 5 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, functional_9_1/dense_33_1/BiasAdd)' with input shapes: [?,10], [?,5]."
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\cleaned_data.csv\")\n",
    "\n",
    "df.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
    "print(df)\n",
    "df = pd.get_dummies(df, columns=['kingdom'], drop_first=True)  # One-hot encoding\n",
    "X = df[['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
    "Y = df[['Avg_Temperature','Avg_Feels_Like_Temperature','Temperature_Range','Feels_Like_Temperature_Range','Radiation', 'Rain_Amount','Rain_Duration' , 'Wind_Speed', 'Wind_Direction','Evapotranspiration']].values\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "time_steps = 30  # Number of past days to use\n",
    "features = X.shape[1]\n",
    "\n",
    "X_seq = []\n",
    "Y_seq = []\n",
    "\n",
    "for i in range(len(X) - time_steps):\n",
    "    X_seq.append(X[i:i+time_steps])  # Past T days as input\n",
    "    Y_seq.append(Y[i+time_steps])    # Predict the next day's values\n",
    "\n",
    "X_seq = np.array(X_seq)  # (samples, time steps, features)\n",
    "Y_seq = np.array(Y_seq)  # (samples, output features)\n",
    "\n",
    "print(X_seq.shape)  # Example: (84957, 3, 32)\n",
    "\n",
    "print(Y_seq.shape)  # Example: (84957, 10)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X[split:]\n",
    "y_train, y_test = Y_seq[:split], y[split:]\n",
    "\n",
    "# ------------------------------- #\n",
    "# Build CNN-LSTM-Attention Model\n",
    "# ------------------------------- #\n",
    "\n",
    "# Define model input\n",
    "input_layer = Input(shape=(TIME_STEPS, X_train.shape[2]))\n",
    "\n",
    "# CNN Layers\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(50, return_sequences=True)(input_layer)\n",
    "\n",
    "# Attention Layer\n",
    "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
    "attention_output = Flatten()(attention_layer)\n",
    "\n",
    "# Merge CNN and LSTM outputs\n",
    "merged = tf.keras.layers.Concatenate()([flatten, attention_output])\n",
    "\n",
    "# Dense Layers\n",
    "dense1 = Dense(64, activation='relu')(merged)\n",
    "dropout1 = Dropout(0.2)(dense1)\n",
    "dense2 = Dense(32, activation='relu')(dropout1)\n",
    "output_layer = Dense(5)(dense2)  # Predicting all 5 variables\n",
    "\n",
    "# Build Model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Train the Model\n",
    "# ------------------------------- #\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c0295ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_22              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,600</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_23              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ lstm_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">274</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,600</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m6,208\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_22              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │          \u001b[38;5;34m16,600\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_23              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ conv1d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_11 (\u001b[38;5;33mAttention\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ lstm_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ lstm_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_21 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_11 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m274\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ flatten_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m17,600\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m165\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,829</span> (190.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,829\u001b[0m (190.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,829</span> (190.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,829\u001b[0m (190.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 27ms/step - loss: 2400.0564 - mae: 23.1023 - val_loss: 1556.8293 - val_mae: 17.8619\n",
      "Epoch 2/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 1022.4367 - mae: 14.2873 - val_loss: 1481.6993 - val_mae: 17.4429\n",
      "Epoch 3/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 956.0984 - mae: 13.4521 - val_loss: 1253.8541 - val_mae: 16.8001\n",
      "Epoch 4/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 934.0187 - mae: 13.1507 - val_loss: 1291.8986 - val_mae: 16.9040\n",
      "Epoch 5/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 905.2960 - mae: 12.7820 - val_loss: 1269.1830 - val_mae: 17.4956\n",
      "Epoch 6/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 871.4365 - mae: 12.5267 - val_loss: 1243.0239 - val_mae: 16.8291\n",
      "Epoch 7/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 859.4841 - mae: 12.3276 - val_loss: 1244.6091 - val_mae: 17.0673\n",
      "Epoch 8/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 843.7935 - mae: 12.1215 - val_loss: 1135.3029 - val_mae: 16.4123\n",
      "Epoch 9/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 826.3730 - mae: 11.9477 - val_loss: 1242.4655 - val_mae: 17.5794\n",
      "Epoch 10/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 825.8819 - mae: 11.9446 - val_loss: 1198.1240 - val_mae: 17.5189\n",
      "Epoch 11/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 801.8929 - mae: 11.7000 - val_loss: 1252.9011 - val_mae: 17.5012\n",
      "Epoch 12/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 798.1865 - mae: 11.6214 - val_loss: 1349.0077 - val_mae: 18.2948\n",
      "Epoch 13/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 800.8055 - mae: 11.6293 - val_loss: 1448.8562 - val_mae: 18.3404\n",
      "Epoch 14/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 788.3786 - mae: 11.5165 - val_loss: 1347.2714 - val_mae: 17.6189\n",
      "Epoch 15/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 775.9823 - mae: 11.3979 - val_loss: 1362.9674 - val_mae: 17.6184\n",
      "Epoch 16/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 766.7352 - mae: 11.3134 - val_loss: 1320.0857 - val_mae: 17.8359\n",
      "Epoch 17/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 760.2502 - mae: 11.2544 - val_loss: 1467.8689 - val_mae: 18.0281\n",
      "Epoch 18/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 740.4700 - mae: 11.0989 - val_loss: 1420.0083 - val_mae: 17.7144\n",
      "Epoch 19/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 747.1828 - mae: 11.1173 - val_loss: 1518.9594 - val_mae: 18.4693\n",
      "Epoch 20/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 721.5132 - mae: 10.9545 - val_loss: 1594.3984 - val_mae: 18.2147\n",
      "Epoch 21/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 716.7851 - mae: 10.8614 - val_loss: 1442.9235 - val_mae: 17.4753\n",
      "Epoch 22/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 706.6124 - mae: 10.7850 - val_loss: 1449.8727 - val_mae: 17.4005\n",
      "Epoch 23/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 705.5730 - mae: 10.7790 - val_loss: 1332.0094 - val_mae: 17.4305\n",
      "Epoch 24/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 692.0829 - mae: 10.6778 - val_loss: 1360.2953 - val_mae: 17.4687\n",
      "Epoch 25/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 674.4952 - mae: 10.5467 - val_loss: 1412.6465 - val_mae: 17.3558\n",
      "Epoch 26/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 660.4338 - mae: 10.4527 - val_loss: 1352.2177 - val_mae: 16.5298\n",
      "Epoch 27/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 647.4475 - mae: 10.3416 - val_loss: 1259.3131 - val_mae: 16.5169\n",
      "Epoch 28/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 658.5231 - mae: 10.3883 - val_loss: 1385.3981 - val_mae: 17.1274\n",
      "Epoch 29/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 640.9462 - mae: 10.2585 - val_loss: 1407.6780 - val_mae: 17.4736\n",
      "Epoch 30/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 29ms/step - loss: 628.0117 - mae: 10.1645 - val_loss: 1338.9442 - val_mae: 16.7031\n",
      "Epoch 31/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 630.8400 - mae: 10.1362 - val_loss: 1296.7439 - val_mae: 16.6678\n",
      "Epoch 32/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 616.9658 - mae: 10.0275 - val_loss: 1289.7065 - val_mae: 16.7212\n",
      "Epoch 33/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 614.5618 - mae: 10.0429 - val_loss: 1223.5144 - val_mae: 15.8478\n",
      "Epoch 34/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 602.1331 - mae: 9.9233 - val_loss: 1255.3171 - val_mae: 16.1305\n",
      "Epoch 35/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 580.5251 - mae: 9.7692 - val_loss: 1317.5397 - val_mae: 16.5750\n",
      "Epoch 36/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 578.6823 - mae: 9.7620 - val_loss: 1203.0712 - val_mae: 16.0254\n",
      "Epoch 37/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 568.0276 - mae: 9.6480 - val_loss: 1288.3887 - val_mae: 16.3617\n",
      "Epoch 38/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 569.6861 - mae: 9.6464 - val_loss: 1188.1908 - val_mae: 15.8126\n",
      "Epoch 39/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 561.3176 - mae: 9.5876 - val_loss: 1248.9348 - val_mae: 16.4108\n",
      "Epoch 40/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 568.7620 - mae: 9.6311 - val_loss: 1273.6075 - val_mae: 16.5061\n",
      "Epoch 41/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 549.0872 - mae: 9.4342 - val_loss: 1220.1243 - val_mae: 15.9787\n",
      "Epoch 42/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 536.6860 - mae: 9.3847 - val_loss: 1212.6688 - val_mae: 15.6707\n",
      "Epoch 43/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 29ms/step - loss: 538.3400 - mae: 9.3394 - val_loss: 1176.5997 - val_mae: 15.6066\n",
      "Epoch 44/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 30ms/step - loss: 521.5305 - mae: 9.2473 - val_loss: 1178.5659 - val_mae: 15.5977\n",
      "Epoch 45/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 30ms/step - loss: 520.9798 - mae: 9.2621 - val_loss: 1244.1552 - val_mae: 15.7784\n",
      "Epoch 46/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - loss: 522.4701 - mae: 9.2283 - val_loss: 1144.4617 - val_mae: 15.2424\n",
      "Epoch 47/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 514.2912 - mae: 9.1724 - val_loss: 1181.8101 - val_mae: 15.2383\n",
      "Epoch 48/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 30ms/step - loss: 514.7288 - mae: 9.1487 - val_loss: 1129.7632 - val_mae: 14.8833\n",
      "Epoch 49/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 30ms/step - loss: 498.3520 - mae: 9.0840 - val_loss: 1137.0984 - val_mae: 15.0004\n",
      "Epoch 50/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 30ms/step - loss: 489.2501 - mae: 8.9667 - val_loss: 1163.2139 - val_mae: 15.1415\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, Attention, Concatenate, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\cleaned_data.csv\")\n",
    "\n",
    "# Sorting\n",
    "df.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
    "\n",
    "# One-hot Encoding\n",
    "df = pd.get_dummies(df, columns=['kingdom'], drop_first=True) \n",
    "\n",
    "# Select Features & Targets\n",
    "X = df[['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
    "Y = df[['Avg_Temperature','Radiation', 'Rain_Amount','Wind_Speed', 'Wind_Direction']].values\n",
    "\n",
    "# Normalize Features\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Prepare Sequential Data\n",
    "time_steps = 30\n",
    "X_seq, Y_seq = [], []\n",
    "\n",
    "for i in range(len(X) - time_steps):\n",
    "    X_seq.append(X[i:i+time_steps])  \n",
    "    Y_seq.append(Y[i+time_steps])    \n",
    "\n",
    "X_seq = np.array(X_seq)  \n",
    "Y_seq = np.array(Y_seq)  \n",
    "\n",
    "# Train-Test Split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
    "\n",
    "# ------------------------------- #\n",
    "# Build CNN-LSTM-Attention Model\n",
    "# ------------------------------- #\n",
    "\n",
    "# Model Input\n",
    "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
    "\n",
    "# CNN Layers\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "cnn_output = Flatten()(pool2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(50, return_sequences=True)(input_layer)\n",
    "\n",
    "# Attention Layer\n",
    "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
    "attention_output = GlobalAveragePooling1D()(attention_layer)\n",
    "\n",
    "# Merge CNN and LSTM outputs\n",
    "merged = Concatenate()([cnn_output, attention_output])\n",
    "\n",
    "# Dense Layers\n",
    "dense1 = Dense(64, activation='relu')(merged)\n",
    "dropout1 = Dropout(0.2)(dense1)\n",
    "dense2 = Dense(32, activation='relu')(dropout1)\n",
    "output_layer = Dense(5)(dense2)  # Predicting 5 variables\n",
    "\n",
    "# Build Model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Train the Model\n",
    "# ------------------------------- #\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7580d8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (67248, 30, 32)\n",
      "X_test shape: (16812, 30, 32)\n",
      "y_train shape: (67248, 5)\n",
      "y_test shape: (16812, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_24              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,600</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_25              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">274</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,600</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │ dense_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m6,208\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_24              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │          \u001b[38;5;34m16,600\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_25              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ conv1d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_12 (\u001b[38;5;33mAttention\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_22 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ attention_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_12 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m274\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ flatten_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m17,600\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m165\u001b[0m │ dense_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,829</span> (190.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,829\u001b[0m (190.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,829</span> (190.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,829\u001b[0m (190.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 29ms/step - loss: 0.0303 - mae: 0.1249 - val_loss: 0.0244 - val_mae: 0.1138\n",
      "Epoch 2/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0189 - mae: 0.0978 - val_loss: 0.0228 - val_mae: 0.1086\n",
      "Epoch 3/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 0.0175 - mae: 0.0936 - val_loss: 0.0225 - val_mae: 0.1077\n",
      "Epoch 4/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 31ms/step - loss: 0.0167 - mae: 0.0910 - val_loss: 0.0218 - val_mae: 0.1050\n",
      "Epoch 5/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 30ms/step - loss: 0.0159 - mae: 0.0885 - val_loss: 0.0210 - val_mae: 0.1029\n",
      "Epoch 6/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0152 - mae: 0.0865 - val_loss: 0.0207 - val_mae: 0.1027\n",
      "Epoch 7/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0147 - mae: 0.0853 - val_loss: 0.0205 - val_mae: 0.1015\n",
      "Epoch 8/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0146 - mae: 0.0843 - val_loss: 0.0204 - val_mae: 0.1010\n",
      "Epoch 9/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0142 - mae: 0.0833 - val_loss: 0.0200 - val_mae: 0.0997\n",
      "Epoch 10/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0140 - mae: 0.0827 - val_loss: 0.0192 - val_mae: 0.0977\n",
      "Epoch 11/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28ms/step - loss: 0.0140 - mae: 0.0823 - val_loss: 0.0198 - val_mae: 0.0989\n",
      "Epoch 12/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0138 - mae: 0.0819 - val_loss: 0.0192 - val_mae: 0.0983\n",
      "Epoch 13/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28ms/step - loss: 0.0135 - mae: 0.0810 - val_loss: 0.0193 - val_mae: 0.0978\n",
      "Epoch 14/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0136 - mae: 0.0812 - val_loss: 0.0194 - val_mae: 0.0978\n",
      "Epoch 15/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0134 - mae: 0.0807 - val_loss: 0.0191 - val_mae: 0.0964\n",
      "Epoch 16/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0132 - mae: 0.0800 - val_loss: 0.0193 - val_mae: 0.0982\n",
      "Epoch 17/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0131 - mae: 0.0797 - val_loss: 0.0190 - val_mae: 0.0963\n",
      "Epoch 18/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0130 - mae: 0.0793 - val_loss: 0.0192 - val_mae: 0.0973\n",
      "Epoch 19/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0130 - mae: 0.0791 - val_loss: 0.0187 - val_mae: 0.0953\n",
      "Epoch 20/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0130 - mae: 0.0790 - val_loss: 0.0188 - val_mae: 0.0957\n",
      "Epoch 21/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0128 - mae: 0.0786 - val_loss: 0.0192 - val_mae: 0.0971\n",
      "Epoch 22/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0128 - mae: 0.0785 - val_loss: 0.0188 - val_mae: 0.0966\n",
      "Epoch 23/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0128 - mae: 0.0785 - val_loss: 0.0192 - val_mae: 0.0965\n",
      "Epoch 24/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0127 - mae: 0.0780 - val_loss: 0.0196 - val_mae: 0.0983\n",
      "Epoch 25/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0126 - mae: 0.0778 - val_loss: 0.0184 - val_mae: 0.0944\n",
      "Epoch 26/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28ms/step - loss: 0.0126 - mae: 0.0776 - val_loss: 0.0190 - val_mae: 0.0962\n",
      "Epoch 27/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28ms/step - loss: 0.0125 - mae: 0.0774 - val_loss: 0.0185 - val_mae: 0.0949\n",
      "Epoch 28/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0125 - mae: 0.0773 - val_loss: 0.0190 - val_mae: 0.0966\n",
      "Epoch 29/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 27ms/step - loss: 0.0123 - mae: 0.0769 - val_loss: 0.0195 - val_mae: 0.0969\n",
      "Epoch 30/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28ms/step - loss: 0.0125 - mae: 0.0773 - val_loss: 0.0189 - val_mae: 0.0953\n",
      "Epoch 31/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28ms/step - loss: 0.0123 - mae: 0.0768 - val_loss: 0.0183 - val_mae: 0.0941\n",
      "Epoch 32/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0125 - mae: 0.0774 - val_loss: 0.0190 - val_mae: 0.0962\n",
      "Epoch 33/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 27ms/step - loss: 0.0123 - mae: 0.0766 - val_loss: 0.0186 - val_mae: 0.0946\n",
      "Epoch 34/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28ms/step - loss: 0.0122 - mae: 0.0764 - val_loss: 0.0185 - val_mae: 0.0946\n",
      "Epoch 35/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0123 - mae: 0.0766 - val_loss: 0.0187 - val_mae: 0.0948\n",
      "Epoch 36/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0121 - mae: 0.0761 - val_loss: 0.0188 - val_mae: 0.0953\n",
      "Epoch 37/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 28ms/step - loss: 0.0121 - mae: 0.0760 - val_loss: 0.0184 - val_mae: 0.0948\n",
      "Epoch 38/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28ms/step - loss: 0.0121 - mae: 0.0760 - val_loss: 0.0183 - val_mae: 0.0940\n",
      "Epoch 39/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 0.0120 - mae: 0.0758 - val_loss: 0.0182 - val_mae: 0.0934\n",
      "Epoch 40/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 30ms/step - loss: 0.0122 - mae: 0.0761 - val_loss: 0.0190 - val_mae: 0.0957\n",
      "Epoch 41/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0120 - mae: 0.0757 - val_loss: 0.0184 - val_mae: 0.0937\n",
      "Epoch 42/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 29ms/step - loss: 0.0120 - mae: 0.0758 - val_loss: 0.0187 - val_mae: 0.0956\n",
      "Epoch 43/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0120 - mae: 0.0755 - val_loss: 0.0181 - val_mae: 0.0928\n",
      "Epoch 44/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 29ms/step - loss: 0.0120 - mae: 0.0756 - val_loss: 0.0188 - val_mae: 0.0954\n",
      "Epoch 45/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 28ms/step - loss: 0.0120 - mae: 0.0757 - val_loss: 0.0193 - val_mae: 0.0964\n",
      "Epoch 46/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 29ms/step - loss: 0.0119 - mae: 0.0753 - val_loss: 0.0191 - val_mae: 0.0965\n",
      "Epoch 47/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 29ms/step - loss: 0.0119 - mae: 0.0753 - val_loss: 0.0186 - val_mae: 0.0941\n",
      "Epoch 48/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 30ms/step - loss: 0.0119 - mae: 0.0754 - val_loss: 0.0188 - val_mae: 0.0957\n",
      "Epoch 49/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 31ms/step - loss: 0.0119 - mae: 0.0753 - val_loss: 0.0188 - val_mae: 0.0951\n",
      "Epoch 50/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 34ms/step - loss: 0.0119 - mae: 0.0751 - val_loss: 0.0180 - val_mae: 0.0931\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load Dataset\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\cleaned_data.csv\")\n",
    "\n",
    "# Sorting\n",
    "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
    "\n",
    "# One-hot Encoding\n",
    "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)  # This removes the 'kingdom' column\n",
    "\n",
    "# Define Time Steps\n",
    "time_steps = 30\n",
    "\n",
    "# Store sequences\n",
    "X_seq, Y_seq = [], []\n",
    "\n",
    "# Group by Kingdom using df1 (original)\n",
    "for kingdom, group in df1.groupby('kingdom'):\n",
    "    # Get corresponding rows from df (one-hot encoded)\n",
    "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
    "    group_Y = group.loc[:, ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']].values\n",
    "\n",
    "    # Normalize Features\n",
    "    scaler_X = MinMaxScaler()\n",
    "    group_X = scaler_X.fit_transform(group_X)\n",
    "    \n",
    "    scaler_Y = MinMaxScaler()\n",
    "    group_Y = scaler_Y.fit_transform(group_Y)\n",
    "\n",
    "    # Generate Time-Series Sequences for This Kingdom\n",
    "    for i in range(len(group_X) - time_steps):\n",
    "        X_seq.append(group_X[i:i+time_steps])  \n",
    "        Y_seq.append(group_Y[i+time_steps])    \n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_seq = np.array(X_seq)\n",
    "Y_seq = np.array(Y_seq)\n",
    "\n",
    "# Train-Test Split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
    "\n",
    "# Print Shape for Debugging\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "# ------------------------------- #\n",
    "# Build CNN-LSTM-Attention Model\n",
    "# ------------------------------- #\n",
    "\n",
    "# Model Input\n",
    "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
    "\n",
    "# CNN Layers\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "cnn_output = Flatten()(pool2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(50, return_sequences=True)(input_layer)\n",
    "\n",
    "# Attention Layer\n",
    "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
    "attention_output = GlobalAveragePooling1D()(attention_layer)\n",
    "\n",
    "# Merge CNN and LSTM outputs\n",
    "merged = Concatenate()([cnn_output, attention_output])\n",
    "\n",
    "# Dense Layers\n",
    "dense1 = Dense(64, activation='relu')(merged)\n",
    "dropout1 = Dropout(0.2)(dense1)\n",
    "dense2 = Dense(32, activation='relu')(dropout1)\n",
    "output_layer = Dense(5)(dense2)  # Predicting 5 variables\n",
    "\n",
    "# Build Model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Train the Model\n",
    "# ------------------------------- #\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d913f3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (67248, 30, 32)\n",
      "X_test shape: (16812, 30, 32)\n",
      "y_train shape: (67248, 5)\n",
      "y_test shape: (16812, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_26              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,968</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">122,944</span> │ flatten_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │ dense_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m6,208\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_26              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m131,968\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m256\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                  │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m16,512\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m16,512\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ dense_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m256\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_23 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m122,944\u001b[0m │ flatten_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m165\u001b[0m │ dense_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,605</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321,605\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,605</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321,605\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 36ms/step - loss: 0.1414 - mae: 0.1864 - val_loss: 0.0291 - val_mae: 0.1265\n",
      "Epoch 2/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 35ms/step - loss: 0.0226 - mae: 0.1086 - val_loss: 0.0274 - val_mae: 0.1241\n",
      "Epoch 3/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 35ms/step - loss: 0.0218 - mae: 0.1063 - val_loss: 0.0228 - val_mae: 0.1106\n",
      "Epoch 4/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 34ms/step - loss: 0.0202 - mae: 0.1017 - val_loss: 0.0251 - val_mae: 0.1154\n",
      "Epoch 5/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 34ms/step - loss: 0.0194 - mae: 0.0993 - val_loss: 0.0223 - val_mae: 0.1095\n",
      "Epoch 6/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 34ms/step - loss: 0.0189 - mae: 0.0973 - val_loss: 0.0229 - val_mae: 0.1091\n",
      "Epoch 7/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 35ms/step - loss: 0.0185 - mae: 0.0963 - val_loss: 0.0213 - val_mae: 0.1041\n",
      "Epoch 8/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 35ms/step - loss: 0.0175 - mae: 0.0936 - val_loss: 0.0220 - val_mae: 0.1071\n",
      "Epoch 9/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 37ms/step - loss: 0.0168 - mae: 0.0916 - val_loss: 0.0199 - val_mae: 0.1008\n",
      "Epoch 10/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 36ms/step - loss: 0.0165 - mae: 0.0906 - val_loss: 0.0226 - val_mae: 0.1084\n",
      "Epoch 11/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 37ms/step - loss: 0.0159 - mae: 0.0887 - val_loss: 0.0211 - val_mae: 0.1038\n",
      "Epoch 12/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 39ms/step - loss: 0.0153 - mae: 0.0871 - val_loss: 0.0208 - val_mae: 0.1019\n",
      "Epoch 13/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 36ms/step - loss: 0.0148 - mae: 0.0851 - val_loss: 0.0195 - val_mae: 0.1003\n",
      "Epoch 14/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 35ms/step - loss: 0.0145 - mae: 0.0842 - val_loss: 0.0192 - val_mae: 0.0988\n",
      "Epoch 15/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 36ms/step - loss: 0.0141 - mae: 0.0830 - val_loss: 0.0222 - val_mae: 0.1079\n",
      "Epoch 16/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 36ms/step - loss: 0.0138 - mae: 0.0819 - val_loss: 0.0186 - val_mae: 0.0952\n",
      "Epoch 17/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 36ms/step - loss: 0.0136 - mae: 0.0810 - val_loss: 0.0195 - val_mae: 0.0987\n",
      "Epoch 18/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 36ms/step - loss: 0.0132 - mae: 0.0798 - val_loss: 0.0191 - val_mae: 0.0973\n",
      "Epoch 19/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 36ms/step - loss: 0.0129 - mae: 0.0789 - val_loss: 0.0185 - val_mae: 0.0952\n",
      "Epoch 20/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 35ms/step - loss: 0.0127 - mae: 0.0782 - val_loss: 0.0188 - val_mae: 0.0956\n",
      "Epoch 21/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 35ms/step - loss: 0.0125 - mae: 0.0775 - val_loss: 0.0185 - val_mae: 0.0948\n",
      "Epoch 22/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 35ms/step - loss: 0.0124 - mae: 0.0770 - val_loss: 0.0192 - val_mae: 0.0978\n",
      "Epoch 23/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 36ms/step - loss: 0.0122 - mae: 0.0764 - val_loss: 0.0198 - val_mae: 0.0999\n",
      "Epoch 24/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 36ms/step - loss: 0.0122 - mae: 0.0759 - val_loss: 0.0184 - val_mae: 0.0952\n",
      "Epoch 25/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 36ms/step - loss: 0.0119 - mae: 0.0753 - val_loss: 0.0193 - val_mae: 0.0970\n",
      "Epoch 26/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 37ms/step - loss: 0.0119 - mae: 0.0751 - val_loss: 0.0178 - val_mae: 0.0933\n",
      "Epoch 27/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 36ms/step - loss: 0.0117 - mae: 0.0744 - val_loss: 0.0177 - val_mae: 0.0928\n",
      "Epoch 28/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 43ms/step - loss: 0.0117 - mae: 0.0743 - val_loss: 0.0180 - val_mae: 0.0945\n",
      "Epoch 29/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 37ms/step - loss: 0.0115 - mae: 0.0738 - val_loss: 0.0201 - val_mae: 0.1009\n",
      "Epoch 30/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 39ms/step - loss: 0.0116 - mae: 0.0740 - val_loss: 0.0176 - val_mae: 0.0912\n",
      "Epoch 31/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 39ms/step - loss: 0.0114 - mae: 0.0732 - val_loss: 0.0177 - val_mae: 0.0921\n",
      "Epoch 32/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 37ms/step - loss: 0.0114 - mae: 0.0731 - val_loss: 0.0176 - val_mae: 0.0907\n",
      "Epoch 33/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 38ms/step - loss: 0.0114 - mae: 0.0731 - val_loss: 0.0180 - val_mae: 0.0932\n",
      "Epoch 34/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 37ms/step - loss: 0.0112 - mae: 0.0725 - val_loss: 0.0183 - val_mae: 0.0943\n",
      "Epoch 35/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 35ms/step - loss: 0.0112 - mae: 0.0724 - val_loss: 0.0177 - val_mae: 0.0921\n",
      "Epoch 36/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 35ms/step - loss: 0.0111 - mae: 0.0720 - val_loss: 0.0184 - val_mae: 0.0946\n",
      "Epoch 37/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 35ms/step - loss: 0.0110 - mae: 0.0718 - val_loss: 0.0189 - val_mae: 0.0955\n",
      "Epoch 38/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 35ms/step - loss: 0.0110 - mae: 0.0718 - val_loss: 0.0175 - val_mae: 0.0913\n",
      "Epoch 39/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 35ms/step - loss: 0.0110 - mae: 0.0715 - val_loss: 0.0189 - val_mae: 0.0958\n",
      "Epoch 40/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 35ms/step - loss: 0.0110 - mae: 0.0715 - val_loss: 0.0184 - val_mae: 0.0927\n",
      "Epoch 41/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 35ms/step - loss: 0.0110 - mae: 0.0714 - val_loss: 0.0187 - val_mae: 0.0942\n",
      "Epoch 42/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 35ms/step - loss: 0.0109 - mae: 0.0710 - val_loss: 0.0185 - val_mae: 0.0939\n",
      "Epoch 43/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 35ms/step - loss: 0.0108 - mae: 0.0709 - val_loss: 0.0181 - val_mae: 0.0925\n",
      "Epoch 44/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 35ms/step - loss: 0.0107 - mae: 0.0707 - val_loss: 0.0187 - val_mae: 0.0948\n",
      "Epoch 45/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 35ms/step - loss: 0.0107 - mae: 0.0705 - val_loss: 0.0182 - val_mae: 0.0931\n",
      "Epoch 46/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 35ms/step - loss: 0.0105 - mae: 0.0699 - val_loss: 0.0189 - val_mae: 0.0955\n",
      "Epoch 47/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 37ms/step - loss: 0.0106 - mae: 0.0700 - val_loss: 0.0186 - val_mae: 0.0949\n",
      "Epoch 48/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 35ms/step - loss: 0.0106 - mae: 0.0700 - val_loss: 0.0174 - val_mae: 0.0907\n",
      "Epoch 49/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 35ms/step - loss: 0.0106 - mae: 0.0701 - val_loss: 0.0180 - val_mae: 0.0917\n",
      "Epoch 50/50\n",
      "\u001b[1m2102/2102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 37ms/step - loss: 0.0106 - mae: 0.0699 - val_loss: 0.0177 - val_mae: 0.0911\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Dataset\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\cleaned_data.csv\")\n",
    "\n",
    "# Sorting\n",
    "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
    "\n",
    "# One-hot Encoding\n",
    "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)  # This removes the 'kingdom' column\n",
    "\n",
    "# Define Time Steps\n",
    "time_steps = 30\n",
    "\n",
    "# Store sequences\n",
    "X_seq, Y_seq = [], []\n",
    "\n",
    "# Group by Kingdom using df1 (original)\n",
    "for kingdom, group in df1.groupby('kingdom'):\n",
    "    # Get corresponding rows from df (one-hot encoded)\n",
    "    group_X = df.loc[group.index, ['Year', 'Month', 'Day'] + [col for col in df.columns if 'kingdom' in col]].values\n",
    "    group_Y = group.loc[:, ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']].values\n",
    "\n",
    "    # Normalize Features\n",
    "    scaler_X = MinMaxScaler()\n",
    "    group_X = scaler_X.fit_transform(group_X)\n",
    "\n",
    "    scaler_Y = MinMaxScaler()\n",
    "    group_Y = scaler_Y.fit_transform(group_Y)\n",
    "\n",
    "    # Generate Time-Series Sequences for This Kingdom\n",
    "    for i in range(len(group_X) - time_steps):\n",
    "        X_seq.append(group_X[i:i+time_steps])\n",
    "        Y_seq.append(group_Y[i+time_steps])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_seq = np.array(X_seq)\n",
    "Y_seq = np.array(Y_seq)\n",
    "\n",
    "# Train-Test Split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
    "\n",
    "# Print Shape for Debugging\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "# ------------------------------- #\n",
    "# Build Transformer Model\n",
    "# ------------------------------- #\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
    "    # Attention layer\n",
    "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
    "    attn_output = tf.keras.layers.Dropout(dropout_rate)(attn_output)\n",
    "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + inputs)  # Skip Connection\n",
    "\n",
    "    # Feed-Forward Network\n",
    "    ff_output = tf.keras.layers.Dense(ff_dim, activation='relu')(attn_output)\n",
    "    ff_output = tf.keras.layers.Dense(inputs.shape[-1])(ff_output)  # Output size matching input\n",
    "    return tf.keras.layers.LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
    "\n",
    "\n",
    "# Model Input\n",
    "input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
    "\n",
    "# CNN Layers\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "\n",
    "# Calculate the new time dimension after pooling\n",
    "new_time_steps = time_steps // 2  # 30 / 2 = 15\n",
    "\n",
    "# Reshaping to match transformer input shape (batch_size, time_steps, feature_size)\n",
    "transformer_input = tf.keras.layers.Reshape((new_time_steps, conv2.shape[-1]))(conv2)\n",
    "\n",
    "# Transformer Encoder\n",
    "transformer_output = transformer_encoder(transformer_input, head_size=64, num_heads=4, ff_dim=128)\n",
    "\n",
    "# Flatten the transformer output\n",
    "flatten = Flatten()(transformer_output)\n",
    "\n",
    "# Dense Layers\n",
    "dense1 = Dense(64, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.2)(dense1)\n",
    "dense2 = Dense(32, activation='relu')(dropout1)\n",
    "output_layer = Dense(5)(dense2)  # Adjusted to match y_train.shape[-1]\n",
    "\n",
    "# Build and compile the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------- #\n",
    "# Train the Model\n",
    "# ------------------------------- #\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LayerNormalization, MultiHeadAttention, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Load Dataset\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\Isitha\\\\Downloads\\\\cleaned_data.csv\")\n",
    "\n",
    "# Ensure column exists\n",
    "if 'Avg_Temperature' not in df1.columns:\n",
    "    raise KeyError(\"Column 'Avg_Temperature' not found in the dataset. Check the CSV file.\")\n",
    "\n",
    "# Sorting\n",
    "df1.sort_values(by=['kingdom', 'Year', 'Month', 'Day'], ascending=True, inplace=True)\n",
    "\n",
    "# Feature Engineering: Seasonal Features\n",
    "df1['sin_month'] = np.sin(2 * np.pi * df1['Month'] / 12)\n",
    "df1['cos_month'] = np.cos(2 * np.pi * df1['Month'] / 12)\n",
    "\n",
    "# One-hot Encoding\n",
    "df = pd.get_dummies(df1, columns=['kingdom'], drop_first=True)\n",
    "\n",
    "# Define Time Steps\n",
    "time_steps = 30\n",
    "X_seq, Y_seq = [], []\n",
    "\n",
    "# Normalize and Generate Time-Series Sequences\n",
    "feature_cols = ['Year', 'Month', 'Day', 'sin_month', 'cos_month'] + [col for col in df.columns if 'kingdom' in col]\n",
    "target_cols = ['Avg_Temperature', 'Radiation', 'Rain_Amount', 'Wind_Speed', 'Wind_Direction']\n",
    "\n",
    "for kingdom, group in df1.groupby('kingdom'):\n",
    "    if not set(target_cols).issubset(group.columns):\n",
    "        raise KeyError(f\"Some target columns are missing in the dataset: {target_cols}\")\n",
    "    \n",
    "    group_X = df.loc[group.index, feature_cols].values\n",
    "    group_Y = group.loc[:, target_cols].values\n",
    "    \n",
    "    scaler_X = MinMaxScaler()\n",
    "    group_X = scaler_X.fit_transform(group_X)\n",
    "    \n",
    "    scaler_Y = MinMaxScaler()\n",
    "    group_Y = scaler_Y.fit_transform(group_Y)\n",
    "    \n",
    "    for i in range(len(group_X) - time_steps):\n",
    "        X_seq.append(group_X[i:i+time_steps])\n",
    "        Y_seq.append(group_Y[i+time_steps])\n",
    "\n",
    "X_seq, Y_seq = np.array(X_seq), np.array(Y_seq)\n",
    "\n",
    "# Train-Test Split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = Y_seq[:split], Y_seq[split:]\n",
    "\n",
    "# Define Transformer Encoder\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)\n",
    "    attn_output = Dropout(dropout_rate)(attn_output)\n",
    "    attn_output = LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
    "    \n",
    "    ff_output = Dense(ff_dim, activation='relu')(attn_output)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    return LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
    "\n",
    "# Bayesian Optimization for Hyperparameter Tuning\n",
    "space = [\n",
    "    Integer(32, 128, name='cnn_filters'),\n",
    "    Integer(2, 8, name='num_heads'),\n",
    "    Real(0.1, 0.5, name='dropout_rate')\n",
    "]\n",
    "\n",
    "def build_and_train_model(params):\n",
    "    cnn_filters, num_heads, dropout_rate = params\n",
    "    input_layer = Input(shape=(time_steps, X_train.shape[2]))\n",
    "    \n",
    "    conv1 = Conv1D(filters=cnn_filters, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "    conv2 = Conv1D(filters=cnn_filters * 2, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "    \n",
    "    new_time_steps = time_steps // 2\n",
    "    transformer_input = Reshape((new_time_steps, conv2.shape[-1]))(conv2)\n",
    "    transformer_output = transformer_encoder(transformer_input, head_size=64, num_heads=num_heads, ff_dim=128, dropout_rate=dropout_rate)\n",
    "    \n",
    "    flatten = Flatten()(transformer_output)\n",
    "    dense1 = Dense(64, activation='relu')(flatten)\n",
    "    dropout1 = Dropout(dropout_rate)(dense1)\n",
    "    dense2 = Dense(32, activation='relu')(dropout1)\n",
    "    output_layer = Dense(len(target_cols))(dense2)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=0)\n",
    "    return min(history.history['val_loss'])\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    return build_and_train_model([params['cnn_filters'], params['num_heads'], params['dropout_rate']])\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "res = gp_minimize(objective, space, n_calls=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "322146a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Feels_Like_Temperature</th>\n",
       "      <th>Temperature_Range</th>\n",
       "      <th>Feels_Like_Temperature_Range</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Rain_Amount</th>\n",
       "      <th>Rain_Duration</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Wind_Direction</th>\n",
       "      <th>Evapotranspiration</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>cos_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "      <td>25.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>22.52</td>\n",
       "      <td>58.89</td>\n",
       "      <td>16</td>\n",
       "      <td>8.6</td>\n",
       "      <td>283</td>\n",
       "      <td>1.648659</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "      <td>25.8</td>\n",
       "      <td>31.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>24.29</td>\n",
       "      <td>16.77</td>\n",
       "      <td>7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>257</td>\n",
       "      <td>1.713798</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.33</td>\n",
       "      <td>8.19</td>\n",
       "      <td>4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>252</td>\n",
       "      <td>1.682688</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "      <td>26.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.35</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>247</td>\n",
       "      <td>1.704748</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>24.280002</td>\n",
       "      <td>-37.229980</td>\n",
       "      <td>27.9</td>\n",
       "      <td>32.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>26.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>256</td>\n",
       "      <td>1.851599</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84839</th>\n",
       "      <td>84840</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>Winterfell</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "      <td>22.4</td>\n",
       "      <td>25.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>22.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>142</td>\n",
       "      <td>1.578979</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84869</th>\n",
       "      <td>84870</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>Winterfell</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "      <td>21.9</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>18.89</td>\n",
       "      <td>3.51</td>\n",
       "      <td>9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>81</td>\n",
       "      <td>1.415853</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84899</th>\n",
       "      <td>84900</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>Winterfell</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "      <td>21.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>23.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>76</td>\n",
       "      <td>1.601406</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84929</th>\n",
       "      <td>84930</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>Winterfell</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>10.8</td>\n",
       "      <td>23.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>66</td>\n",
       "      <td>1.587192</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84959</th>\n",
       "      <td>84960</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Winterfell</td>\n",
       "      <td>23.979999</td>\n",
       "      <td>-36.429994</td>\n",
       "      <td>20.1</td>\n",
       "      <td>21.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>21.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>53</td>\n",
       "      <td>1.539015</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84960 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Year  Month  Day     kingdom   latitude  longitude  \\\n",
       "0          1     1      4    1     Arcadia  24.280002 -37.229980   \n",
       "30        31     1      4    2     Arcadia  24.280002 -37.229980   \n",
       "60        61     1      4    3     Arcadia  24.280002 -37.229980   \n",
       "90        91     1      4    4     Arcadia  24.280002 -37.229980   \n",
       "120      121     1      4    5     Arcadia  24.280002 -37.229980   \n",
       "...      ...   ...    ...  ...         ...        ...        ...   \n",
       "84839  84840     8     12   27  Winterfell  23.979999 -36.429994   \n",
       "84869  84870     8     12   28  Winterfell  23.979999 -36.429994   \n",
       "84899  84900     8     12   29  Winterfell  23.979999 -36.429994   \n",
       "84929  84930     8     12   30  Winterfell  23.979999 -36.429994   \n",
       "84959  84960     8     12   31  Winterfell  23.979999 -36.429994   \n",
       "\n",
       "       Avg_Temperature  Avg_Feels_Like_Temperature  Temperature_Range  \\\n",
       "0                 25.5                        30.5                8.5   \n",
       "30                25.8                        31.1                8.7   \n",
       "60                26.0                        30.9                7.5   \n",
       "90                26.7                        31.6                8.1   \n",
       "120               27.9                        32.8               10.1   \n",
       "...                ...                         ...                ...   \n",
       "84839             22.4                        25.5                7.6   \n",
       "84869             21.9                        25.0                5.6   \n",
       "84899             21.8                        24.0                6.4   \n",
       "84929             20.3                        21.8                8.1   \n",
       "84959             20.1                        21.5                8.4   \n",
       "\n",
       "       Feels_Like_Temperature_Range  Radiation  Rain_Amount  Rain_Duration  \\\n",
       "0                              10.3      22.52        58.89             16   \n",
       "30                             11.4      24.29        16.77              7   \n",
       "60                             10.0      23.33         8.19              4   \n",
       "90                             10.0      23.35         0.91              3   \n",
       "120                            12.8      26.85         0.00              0   \n",
       "...                             ...        ...          ...            ...   \n",
       "84839                           8.8      22.18         0.26              2   \n",
       "84869                           7.1      18.89         3.51              9   \n",
       "84899                           7.3      23.23         0.00              0   \n",
       "84929                          10.8      23.35         0.00              0   \n",
       "84959                          11.1      21.31         0.00              0   \n",
       "\n",
       "       Wind_Speed  Wind_Direction  Evapotranspiration     sin_month  cos_month  \n",
       "0             8.6             283            1.648659  8.660254e-01       -0.5  \n",
       "30            9.4             257            1.713798  8.660254e-01       -0.5  \n",
       "60            9.4             252            1.682688  8.660254e-01       -0.5  \n",
       "90           10.4             247            1.704748  8.660254e-01       -0.5  \n",
       "120          10.6             256            1.851599  8.660254e-01       -0.5  \n",
       "...           ...             ...                 ...           ...        ...  \n",
       "84839         8.7             142            1.578979 -2.449294e-16        1.0  \n",
       "84869        10.5              81            1.415853 -2.449294e-16        1.0  \n",
       "84899        12.6              76            1.601406 -2.449294e-16        1.0  \n",
       "84929        10.7              66            1.587192 -2.449294e-16        1.0  \n",
       "84959         9.4              53            1.539015 -2.449294e-16        1.0  \n",
       "\n",
       "[84960 rows x 19 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "37b35b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                              0\n",
      "Year                            0\n",
      "Month                           0\n",
      "Day                             0\n",
      "kingdom                         0\n",
      "latitude                        0\n",
      "longitude                       0\n",
      "Avg_Temperature                 0\n",
      "Avg_Feels_Like_Temperature      0\n",
      "Temperature_Range               0\n",
      "Feels_Like_Temperature_Range    0\n",
      "Radiation                       0\n",
      "Rain_Amount                     0\n",
      "Rain_Duration                   0\n",
      "Wind_Speed                      0\n",
      "Wind_Direction                  0\n",
      "Evapotranspiration              0\n",
      "sin_month                       0\n",
      "cos_month                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5aacbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
